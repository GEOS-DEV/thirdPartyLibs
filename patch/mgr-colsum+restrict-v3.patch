diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index e20557db7..765c490e9 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -149,6 +149,7 @@ set_hypre_option(BASE HYPRE_ENABLE_LTO                  "Use Link-Time Optimizat
 set_hypre_option(BASE HYPRE_ENABLE_PRINT_ERRORS         "Print HYPRE errors" OFF)
 set_hypre_option(SKIP HYPRE_ENABLE_TIMING               "Use HYPRE timing routines" OFF)
 set_hypre_option(SKIP HYPRE_ENABLE_STRICT_CHECKING      "Use strict error checking (Sequential only)" OFF)
+set_hypre_option(SKIP HYPRE_ENABLE_MEMORY_TRACKER       "Use internal memory tracker (Debug only)" OFF)
 set_hypre_option(BASE HYPRE_ENABLE_TEST_USING_HOST      "Execute tests on host (CPU)" OFF)
 set_hypre_option(BASE HYPRE_ENABLE_HOST_MEMORY          "Use host memory" ON)
 set_hypre_option(BASE HYPRE_BUILD_EXAMPLES              "Build examples" OFF)
@@ -232,6 +233,7 @@ set_internal_hypre_option("" TEST_USING_HOST)
 set_internal_hypre_option("" PRINT_ERRORS)
 set_internal_hypre_option(USING HYPRE_BLAS)
 set_internal_hypre_option(USING HYPRE_LAPACK)
+set_internal_hypre_option(USING MEMORY_TRACKER)
 set_internal_hypre_option(USING HOPSCOTCH)
 set_internal_hypre_option(USING GPU_AWARE_MPI)
 set_internal_hypre_option(USING GPU_STREAMS)
diff --git a/src/config/HYPRE_config.h.cmake.in b/src/config/HYPRE_config.h.cmake.in
index af8ac492c..1cec66669 100644
--- a/src/config/HYPRE_config.h.cmake.in
+++ b/src/config/HYPRE_config.h.cmake.in
@@ -65,6 +65,9 @@
 /* Use internal LAPACK library */
 #cmakedefine HYPRE_USING_HYPRE_LAPACK 1
 
+/* Use internal memory tracker */
+#cmakedefine HYPRE_USING_MEMORY_TRACKER 1
+
 /* Print HYPRE errors */
 #cmakedefine HYPRE_PRINT_ERRORS 1
 
diff --git a/src/config/cmake/HYPRE_SetupHIPToolkit.cmake b/src/config/cmake/HYPRE_SetupHIPToolkit.cmake
index 6d8848642..656b5c8f5 100644
--- a/src/config/cmake/HYPRE_SetupHIPToolkit.cmake
+++ b/src/config/cmake/HYPRE_SetupHIPToolkit.cmake
@@ -144,16 +144,27 @@ find_and_add_rocm_library(rocrand)
 find_and_add_rocm_library(rocsolver)
 
 if(HYPRE_ENABLE_GPU_PROFILING)
-  set(HYPRE_USING_ROCTRACER ON CACHE BOOL "" FORCE)
+  set(HYPRE_USING_ROCTX ON CACHE BOOL "" FORCE)
   find_library(ROCTRACER_LIBRARY
      NAMES libroctracer64.so
      PATHS ${HIP_PATH}/lib ${HIP_PATH}/lib64
      NO_DEFAULT_PATH)
   if(ROCTRACER_LIBRARY)
-    message(STATUS "ROCm tracer library found in ${ROCTRACER_LIBRARY}")
+    message(STATUS "ROCTracer library found in ${ROCTRACER_LIBRARY}")
     list(APPEND ROCM_LIBS ${ROCTRACER_LIBRARY})
   else()
-    message(WARNING "ROCm tracer library not found. GPU profiling may not work correctly.")
+    message(WARNING "ROCTracer library not found. GPU profiling may not work correctly.")
+  endif()
+
+  find_library(ROCTX_LIBRARY
+     NAMES libroctx64.so
+     PATHS ${HIP_PATH}/lib ${HIP_PATH}/lib64
+     NO_DEFAULT_PATH)
+  if(ROCTX_LIBRARY)
+    message(STATUS "ROC-TX library found in ${ROCTX_LIBRARY}")
+    list(APPEND ROCM_LIBS ${ROCTX_LIBRARY})
+  else()
+    message(WARNING "ROC-TX library not found. GPU profiling may not work correctly.")
   endif()
 endif()
 
diff --git a/src/parcsr_ls/_hypre_parcsr_ls.h b/src/parcsr_ls/_hypre_parcsr_ls.h
index 3c62f514f..ae8a0c591 100644
--- a/src/parcsr_ls/_hypre_parcsr_ls.h
+++ b/src/parcsr_ls/_hypre_parcsr_ls.h
@@ -3789,6 +3789,8 @@ HYPRE_Int hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix *A, HYPRE_
                                                    HYPRE_Int point_type, HYPRE_Int *CF_marker,
                                                    HYPRE_Int diag_type,
                                                    hypre_ParCSRMatrix **B_ptr );
+HYPRE_Int hypre_MGRBuildRFromWrDevice(hypre_IntArray *C_map, hypre_IntArray *F_map,
+                                      hypre_ParCSRMatrix *Wr, hypre_ParCSRMatrix *R);
 
 /* par_mgr_stats.c */
 HYPRE_Int hypre_MGRSetupStats( void *mgr_vdata );
diff --git a/src/parcsr_ls/par_mgr_device.c b/src/parcsr_ls/par_mgr_device.c
index 8c18b6255..9eafd7273 100644
--- a/src/parcsr_ls/par_mgr_device.c
+++ b/src/parcsr_ls/par_mgr_device.c
@@ -1004,4 +1004,119 @@ hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix  *A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ * Constructs a classical restriction operator as R = [Wr I] on GPU.
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_MGRBuildRFromWrDevice(hypre_IntArray      *C_map,
+                            hypre_IntArray      *F_map,
+                            hypre_ParCSRMatrix  *Wr,
+                            hypre_ParCSRMatrix  *R)
+{
+   /* Input matrix variables */
+   hypre_CSRMatrix       *Wr_diag          = hypre_ParCSRMatrixDiag(Wr);
+   HYPRE_Int             *Wr_diag_i        = hypre_CSRMatrixI(Wr_diag);
+   HYPRE_Int             *Wr_diag_j        = hypre_CSRMatrixJ(Wr_diag);
+   HYPRE_Complex         *Wr_diag_a        = hypre_CSRMatrixData(Wr_diag);
+   HYPRE_Int              Wr_diag_num_rows = hypre_CSRMatrixNumRows(Wr_diag);
+   HYPRE_Int             *C_map_data       = hypre_IntArrayData(C_map);
+   HYPRE_Int             *F_map_data       = hypre_IntArrayData(F_map);
+
+   /* Output matrix */
+   hypre_CSRMatrix       *R_diag           = hypre_ParCSRMatrixDiag(R);
+   HYPRE_Int             *R_diag_i         = hypre_CSRMatrixI(R_diag);
+   HYPRE_Int             *R_diag_j         = hypre_CSRMatrixJ(R_diag);
+   HYPRE_Complex         *R_diag_a         = hypre_CSRMatrixData(R_diag);
+
+   HYPRE_Int              nrows            = Wr_diag_num_rows;
+
+   /* 1. Compute row lengths: 1 (for I) + nnz in Wr row */
+   HYPRE_Int *row_lengths = hypre_TAlloc(HYPRE_Int, nrows, HYPRE_MEMORY_DEVICE);
+
+#if defined(HYPRE_USING_SYCL)
+   oneapi::dpl::counting_iterator<HYPRE_Int> row_begin(0);
+   HYPRE_ONEDPL_CALL(std::transform,
+                     row_begin, row_begin + nrows,
+                     row_lengths,
+                     [=](HYPRE_Int i) {
+                        return (1 + Wr_diag_i[i + 1] - Wr_diag_i[i]);
+                     });
+#else
+   HYPRE_THRUST_CALL(transform,
+                     thrust::make_counting_iterator<HYPRE_Int>(0),
+                     thrust::make_counting_iterator<HYPRE_Int>(nrows),
+                     row_lengths,
+                     [=] __device__ (HYPRE_Int i) {
+                        return (1 + Wr_diag_i[i + 1] - Wr_diag_i[i]);
+                     });
+#endif
+
+   /* 2. Inclusive scan to get R_diag_i */
+   HYPRE_Int zero = 0;
+   hypre_TMemcpy(R_diag_i, &zero, HYPRE_Int, 1, HYPRE_MEMORY_DEVICE, HYPRE_MEMORY_HOST);
+
+#if defined(HYPRE_USING_SYCL)
+   HYPRE_ONEDPL_CALL(std::inclusive_scan,
+                     row_lengths, row_lengths + nrows,
+                     R_diag_i + 1);
+#else
+   HYPRE_THRUST_CALL(inclusive_scan,
+                     row_lengths, row_lengths + nrows,
+                     R_diag_i + 1);
+#endif
+
+   // 3. Fill R_diag_j and R_diag_a in parallel, one row per thread
+#if defined(HYPRE_USING_SYCL)
+   HYPRE_ONEDPL_CALL(std::for_each,
+                     row_begin, row_begin + nrows,
+                     [=](HYPRE_Int i)
+   {
+      HYPRE_Int r_offset = R_diag_i[i];
+
+      /* I part */
+      R_diag_j[r_offset] = C_map_data[i];
+      R_diag_a[r_offset] = 1.0;
+      r_offset++;
+
+      /* Wr part */
+      for (HYPRE_Int jj = Wr_diag_i[i]; jj < Wr_diag_i[i+1]; jj++)
+      {
+         R_diag_j[r_offset] = F_map_data[Wr_diag_j[jj]];
+         R_diag_a[r_offset] = Wr_diag_a[jj];
+         r_offset++;
+      }
+   });
+#else
+   HYPRE_THRUST_CALL(for_each,
+                     thrust::make_counting_iterator<HYPRE_Int>(0),
+                     thrust::make_counting_iterator<HYPRE_Int>(nrows),
+                     [=] __device__ (HYPRE_Int i)
+   {
+      HYPRE_Int r_offset = R_diag_i[i];
+
+      /* I part */
+      R_diag_j[r_offset] = C_map_data[i];
+      R_diag_a[r_offset] = 1.0;
+      r_offset++;
+
+      /* Wr part */
+      for (HYPRE_Int jj = Wr_diag_i[i]; jj < Wr_diag_i[i+1]; jj++)
+      {
+         R_diag_j[r_offset] = F_map_data[Wr_diag_j[jj]];
+         R_diag_a[r_offset] = Wr_diag_a[jj];
+         r_offset++;
+      }
+   });
+#endif
+
+   /* 4. Free row_lengths */
+   hypre_TFree(row_lengths, HYPRE_MEMORY_DEVICE);
+
+   /* 5. Sync compute stream so that R_diag is ready for use */
+   hypre_SyncComputeStream();
+
+   return hypre_error_flag;
+}
+
 #endif
diff --git a/src/parcsr_ls/par_mgr_interp.c b/src/parcsr_ls/par_mgr_interp.c
index a1e2019a5..e2135b66e 100644
--- a/src/parcsr_ls/par_mgr_interp.c
+++ b/src/parcsr_ls/par_mgr_interp.c
@@ -786,10 +786,10 @@ hypre_MGRBuildPHost( hypre_ParCSRMatrix   *A,
          // L1-Jacobi-type interpolation
          diag_FF = hypre_CTAlloc(HYPRE_Complex, num_rows_AFF, memory_location_P);
          hypre_CSRMatrixExtractDiagonalHost(hypre_ParCSRMatrixDiag(A_FF), diag, 0);
-         hypre_CSRMatrixComputeRowSumHost(A_FF_diag, NULL, NULL, diag_FF, 1, 1.0, "set");
-         hypre_CSRMatrixComputeRowSumHost(A_FC_diag, NULL, NULL, diag_FF, 1, 1.0, "add");
-         hypre_CSRMatrixComputeRowSumHost(A_FF_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
-         hypre_CSRMatrixComputeRowSumHost(A_FC_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FF_diag, NULL, NULL, diag_FF, 1, 1.0, "set");
+         hypre_CSRMatrixComputeRowSum(A_FC_diag, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FF_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FC_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
 
          for (i = 0; i < num_rows_AFF; i++)
          {
@@ -2405,14 +2405,7 @@ hypre_MGRBuildRFromWr(hypre_IntArray       *C_map,
 
    if (exec == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): Implement hypre_MGRBuildRFromWrDevice */
-      hypre_ParCSRMatrixMigrate(Wr, HYPRE_MEMORY_HOST);
-      hypre_ParCSRMatrixMigrate(R, HYPRE_MEMORY_HOST);
-      hypre_IntArrayMigrate(C_map, HYPRE_MEMORY_HOST);
-      hypre_IntArrayMigrate(F_map, HYPRE_MEMORY_HOST);
-      hypre_MGRBuildRFromWrHost(C_map, F_map, Wr, R);
-      hypre_ParCSRMatrixMigrate(Wr, HYPRE_MEMORY_DEVICE);
-      hypre_ParCSRMatrixMigrate(R, HYPRE_MEMORY_DEVICE);
+      hypre_MGRBuildRFromWrDevice(C_map, F_map, Wr, R);
    }
    else
 #endif
diff --git a/src/parcsr_ls/protos.h b/src/parcsr_ls/protos.h
index d9bfde521..b8621b197 100644
--- a/src/parcsr_ls/protos.h
+++ b/src/parcsr_ls/protos.h
@@ -2334,6 +2334,8 @@ HYPRE_Int hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix *A, HYPRE_
                                                    HYPRE_Int point_type, HYPRE_Int *CF_marker,
                                                    HYPRE_Int diag_type,
                                                    hypre_ParCSRMatrix **B_ptr );
+HYPRE_Int hypre_MGRBuildRFromWrDevice(hypre_IntArray *C_map, hypre_IntArray *F_map,
+                                      hypre_ParCSRMatrix *Wr, hypre_ParCSRMatrix *R);
 
 /* par_mgr_stats.c */
 HYPRE_Int hypre_MGRSetupStats( void *mgr_vdata );
diff --git a/src/parcsr_mv/_hypre_parcsr_mv.h b/src/parcsr_mv/_hypre_parcsr_mv.h
index a83178afc..249026188 100644
--- a/src/parcsr_mv/_hypre_parcsr_mv.h
+++ b/src/parcsr_mv/_hypre_parcsr_mv.h
@@ -1037,6 +1037,7 @@ HYPRE_Int hypre_ParCSRDiagScaleVectorHost( hypre_ParCSRMatrix *par_A, hypre_ParV
                                            hypre_ParVector *par_x );
 HYPRE_Int hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A, hypre_ParVector *par_y,
                                              hypre_ParVector *par_x );
+HYPRE_Int hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A, hypre_ParVector *b );
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntries( hypre_ParCSRMatrix *A, HYPRE_Real tol,
                                               HYPRE_Int type);
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntriesHost( hypre_ParCSRMatrix *A, HYPRE_Real tol,
@@ -1282,6 +1283,7 @@ HYPRE_Int hypre_ParVectorSetNumTags( hypre_ParVector *vector, HYPRE_Int num_tags
 HYPRE_Int hypre_ParVectorSetTags( hypre_ParVector *vector,
                                   HYPRE_MemoryLocation memory_location,
                                   HYPRE_Int *tags );
+HYPRE_Int hypre_ParVectorSetValuesTagged(hypre_ParVector *vector, HYPRE_Complex *values);
 HYPRE_Int hypre_ParVectorInitialize ( hypre_ParVector *vector );
 HYPRE_Int hypre_ParVectorInitialize_v2( hypre_ParVector *vector,
                                         HYPRE_MemoryLocation memory_location );
diff --git a/src/parcsr_mv/par_csr_matop.c b/src/parcsr_mv/par_csr_matop.c
index 8ce40413b..1d5b095af 100644
--- a/src/parcsr_mv/par_csr_matop.c
+++ b/src/parcsr_mv/par_csr_matop.c
@@ -7033,12 +7033,7 @@ hypre_ParCSRMatrixColSum( hypre_ParCSRMatrix   *A,
 
    if (exec == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): hypre_ParCSRMatrixColSumDevice */
-      hypre_ParCSRMatrixMigrate(A, HYPRE_MEMORY_HOST);
-      hypre_ParVectorMigrate(b, HYPRE_MEMORY_HOST);
-      hypre_ParCSRMatrixColSumHost(A, b);
-      hypre_ParCSRMatrixMigrate(A, HYPRE_MEMORY_DEVICE);
-      hypre_ParVectorMigrate(b, HYPRE_MEMORY_DEVICE);
+      hypre_ParCSRMatrixColSumDevice(A, b);
    }
    else
 #endif
@@ -7102,8 +7097,10 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
 
    hypre_CSRMatrix         *A_diag          = hypre_ParCSRMatrixDiag(A);
    HYPRE_Real              *tnorms          = NULL;
-   HYPRE_Real              *weights         = NULL;
+   HYPRE_Real              *local_weights   = NULL;
    HYPRE_Real              *g_weights       = NULL;
+   HYPRE_Real              *weights         = NULL;
+   HYPRE_Real               tnorm;
    HYPRE_Int                i;
 
    /* Sanity check - Return an empty scaling if tags is a null pointer or type = 0 */
@@ -7114,6 +7111,8 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
       return hypre_error_flag;
    }
 
+   HYPRE_ANNOTATE_FUNC_BEGIN;
+
    /* Create and initialize scaling vector if it does not exist yet */
    if (!*scaling_ptr)
    {
@@ -7126,49 +7125,88 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
       hypre_ParVectorResize(*scaling_ptr, num_rows, 1);
    }
 
-   if (type == 1)
+   /* Set tags array if needed */
+   if (!hypre_ParVectorTags(*scaling_ptr) ||
+       num_tags != hypre_ParVectorNumTags(*scaling_ptr))
    {
-      /* Move scaling vector to host memory if needed */
-      hypre_ParVectorMigrate(*scaling_ptr, HYPRE_MEMORY_HOST);
+      hypre_ParVectorSetOwnsTags(*scaling_ptr, 1);
+      hypre_ParVectorSetNumTags(*scaling_ptr, num_tags);
+      hypre_ParVectorSetTags(*scaling_ptr, HYPRE_MEMORY_HOST, tags);
+   }
 
+   if (type == 1)
+   {
       /* Compute Frobenius norms */
-      hypre_CSRMatrixTaggedFnorm(A_diag, num_tags, tags, &tnorms);
+      hypre_CSRMatrixTaggedFnorm(A_diag, num_tags, hypre_ParVectorTags(*scaling_ptr), &tnorms);
 
       /* Compute local scaling weights */
-      weights = hypre_TAlloc(HYPRE_Real, num_tags, HYPRE_MEMORY_HOST);
+      local_weights = hypre_TAlloc(HYPRE_Real, num_tags, HYPRE_MEMORY_HOST);
       for (i = 0; i < num_tags; i++)
       {
-         weights[i] = hypre_squared(tnorms[i * num_tags + i]);
+         tnorm = tnorms[i * num_tags + i];
+         local_weights[i] = (tnorm > 0.0) ? hypre_squared(tnorm) : 1.0;
       }
 
       /* Compute global scaling weights */
       g_weights = hypre_TAlloc(HYPRE_Real, num_tags, HYPRE_MEMORY_HOST);
-      hypre_MPI_Allreduce(weights, g_weights, num_tags, MPI_DOUBLE, MPI_SUM, comm);
+#if defined(HYPRE_USING_GPU)
+      HYPRE_ExecutionPolicy exec = hypre_GetExecPolicy1(memory_location);
+
+      if (exec == HYPRE_EXEC_DEVICE)
+      {
+         weights = hypre_TAlloc(HYPRE_Real, num_tags, HYPRE_MEMORY_DEVICE);
+      }
+      else
+#endif
+      {
+         weights = g_weights;
+      }
+
+      hypre_MPI_Allreduce(local_weights, g_weights, num_tags, MPI_DOUBLE, MPI_SUM, comm);
       for (i = 0; i < num_tags; i++)
       {
-         g_weights[i] = pow(10.0, round(log10(hypre_sqrt(1.0 / g_weights[i]))));
+         g_weights[i] = hypre_sqrt(pow(10.0,
+                                       2 * round( log10(hypre_sqrt(1.0 / g_weights[i])) / 2.0 )));
       }
 
-      /* Setup scaling vector */
-      for (i = 0; i < num_rows; i++)
+      if (weights != g_weights)
+      {
+         hypre_TMemcpy(weights, g_weights, HYPRE_Real, num_tags,
+                       HYPRE_MEMORY_DEVICE, HYPRE_MEMORY_HOST);
+      }
+
+#if 0
+      /* Debug weights */
+      hypre_ParPrintf(comm, "%s - Scaling weights: [ ", __func__);
+      for (i = 0; i < num_tags; i++)
       {
-         hypre_ParVectorEntryI(*scaling_ptr, i) = hypre_sqrt(g_weights[tags[i]]);
+         hypre_ParPrintf(comm, "%.0e ", g_weights[i]);
       }
+      hypre_ParPrintf(comm, "]\n");
+      hypre_MPI_Barrier(comm);
+#endif
 
-      /* Migrate scaling vector to destination memory location */
-      hypre_ParVectorMigrate(*scaling_ptr, memory_location);
+      /* Setup scaling vector */
+      hypre_ParVectorSetValuesTagged(*scaling_ptr, weights);
 
       /* Free memory */
       hypre_TFree(tnorms, HYPRE_MEMORY_HOST);
-      hypre_TFree(weights, HYPRE_MEMORY_HOST);
+      hypre_TFree(local_weights, HYPRE_MEMORY_HOST);
       hypre_TFree(g_weights, HYPRE_MEMORY_HOST);
+      if (weights != g_weights)
+      {
+         hypre_TFree(weights, HYPRE_MEMORY_DEVICE);
+      }
    }
    else
    {
-      *scaling_ptr = NULL;
       hypre_error_w_msg(HYPRE_ERROR_GENERIC, "Invalid scaling type");
+      HYPRE_ANNOTATE_FUNC_END;
+
       return hypre_error_flag;
    }
 
+   HYPRE_ANNOTATE_FUNC_END;
+
    return hypre_error_flag;
 }
diff --git a/src/parcsr_mv/par_csr_matop_device.c b/src/parcsr_mv/par_csr_matop_device.c
index 77fdd6503..94ecdd16a 100644
--- a/src/parcsr_mv/par_csr_matop_device.c
+++ b/src/parcsr_mv/par_csr_matop_device.c
@@ -2025,4 +2025,88 @@ hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A,
+                                hypre_ParVector    *b )
+{
+   hypre_ParCSRCommPkg    *comm_pkg       = hypre_ParCSRMatrixCommPkg(A);
+   hypre_CSRMatrix        *A_diag         = hypre_ParCSRMatrixDiag(A);
+   hypre_CSRMatrix        *A_offd         = hypre_ParCSRMatrixOffd(A);
+   HYPRE_Int               num_cols_diag  = hypre_CSRMatrixNumCols(A_diag);
+   HYPRE_Int               num_cols_offd  = hypre_CSRMatrixNumCols(A_offd);
+   HYPRE_Complex          *b_data         = hypre_ParVectorLocalData(b);
+   HYPRE_Int               num_sends      = hypre_ParCSRCommPkgNumSends(comm_pkg);
+   HYPRE_Int               send_map_num_elmts = hypre_ParCSRCommPkgSendMapStart(comm_pkg, num_sends);
+
+   hypre_ParCSRCommHandle *comm_handle;
+   HYPRE_Complex          *d_send_buf;
+   HYPRE_Complex          *d_recv_buf;
+
+   /*---------------------------------------------------------------------
+    * Allocate/reuse data buffers
+    *--------------------------------------------------------------------*/
+
+   if (!hypre_ParCSRCommPkgTmpData(comm_pkg))
+   {
+      hypre_ParCSRCommPkgTmpData(comm_pkg) = hypre_TAlloc(HYPRE_Complex,
+                                                          num_cols_offd,
+                                                          HYPRE_MEMORY_DEVICE);
+   }
+   d_send_buf = hypre_ParCSRCommPkgTmpData(comm_pkg);
+   hypreDevice_ComplexFilln(d_send_buf, num_cols_offd, 0.0);
+
+   /* send_map_elmts on device */
+   hypre_ParCSRCommPkgCopySendMapElmtsToDevice(comm_pkg);
+
+   /* Allocate receive data buffer */
+   if (!hypre_ParCSRCommPkgBufData(comm_pkg))
+   {
+      hypre_ParCSRCommPkgBufData(comm_pkg) = hypre_TAlloc(HYPRE_Complex,
+                                                          send_map_num_elmts,
+                                                          HYPRE_MEMORY_DEVICE);
+   }
+   d_recv_buf = hypre_ParCSRCommPkgBufData(comm_pkg);
+
+   /*---------------------------------------------------------------------
+    * Overlap communication and computation
+    *--------------------------------------------------------------------*/
+
+   /* Compute off-diagonal contribution to be sent to neighboring ranks */
+   hypre_CSRMatrixComputeColSum(A_offd, d_send_buf, 0, 1.0);
+
+   /* Make sure d_send_buf is ready before communicating it */
+   if (hypre_GetGpuAwareMPI())
+   {
+      hypre_ForceSyncComputeStream();
+   }
+
+   /* Non-blocking communication starts */
+   comm_handle = hypre_ParCSRCommHandleCreate_v2(2, comm_pkg,
+                                                 HYPRE_MEMORY_DEVICE, d_send_buf,
+                                                 HYPRE_MEMORY_DEVICE, d_recv_buf );
+
+   /* Compute diagonal contribution */
+   hypre_CSRMatrixComputeColSum(A_diag, b_data, 0, 1.0);
+
+   /* Non-blocking communication ends */
+   hypre_ParCSRCommHandleDestroy(comm_handle);
+
+   /* Make sure b_data is ready before updating it below */
+   if (hypre_GetGpuAwareMPI())
+   {
+      hypre_ForceSyncComputeStream();
+   }
+
+   /* Compute off-diagonal contribution by unpacking data via SpMV */
+   hypre_ParCSRMatrixMatvecT_unpack(comm_pkg, num_cols_diag, d_recv_buf, b_data);
+
+   /* Final sync to ensure all updates are complete before returning */
+   hypre_SyncComputeStream();
+
+   return hypre_error_flag;
+}
+
 #endif // #if defined(HYPRE_USING_GPU) || defined(HYPRE_USING_DEVICE_OPENMP)
diff --git a/src/parcsr_mv/par_vector.c b/src/parcsr_mv/par_vector.c
index bf228d13c..36e74fed1 100644
--- a/src/parcsr_mv/par_vector.c
+++ b/src/parcsr_mv/par_vector.c
@@ -188,6 +188,18 @@ hypre_ParVectorSetTags(hypre_ParVector      *vector,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_ParVectorSetValuesTagged(hypre_ParVector  *vector,
+                               HYPRE_Complex    *values)
+{
+   hypre_SeqVectorSetValuesTagged(hypre_ParVectorLocalVector(vector), values);
+
+   return hypre_error_flag;
+}
+
 /*--------------------------------------------------------------------------
  * hypre_ParVectorInitialize_v2
  *
diff --git a/src/parcsr_mv/protos.h b/src/parcsr_mv/protos.h
index 02479f140..de9106b90 100644
--- a/src/parcsr_mv/protos.h
+++ b/src/parcsr_mv/protos.h
@@ -373,6 +373,7 @@ HYPRE_Int hypre_ParCSRDiagScaleVectorHost( hypre_ParCSRMatrix *par_A, hypre_ParV
                                            hypre_ParVector *par_x );
 HYPRE_Int hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A, hypre_ParVector *par_y,
                                              hypre_ParVector *par_x );
+HYPRE_Int hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A, hypre_ParVector *b );
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntries( hypre_ParCSRMatrix *A, HYPRE_Real tol,
                                               HYPRE_Int type);
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntriesHost( hypre_ParCSRMatrix *A, HYPRE_Real tol,
@@ -618,6 +619,7 @@ HYPRE_Int hypre_ParVectorSetNumTags( hypre_ParVector *vector, HYPRE_Int num_tags
 HYPRE_Int hypre_ParVectorSetTags( hypre_ParVector *vector,
                                   HYPRE_MemoryLocation memory_location,
                                   HYPRE_Int *tags );
+HYPRE_Int hypre_ParVectorSetValuesTagged(hypre_ParVector *vector, HYPRE_Complex *values);
 HYPRE_Int hypre_ParVectorInitialize ( hypre_ParVector *vector );
 HYPRE_Int hypre_ParVectorInitialize_v2( hypre_ParVector *vector,
                                         HYPRE_MemoryLocation memory_location );
diff --git a/src/seq_mv/csr_matop.c b/src/seq_mv/csr_matop.c
index 5d614cdcb..ffc5e97a0 100644
--- a/src/seq_mv/csr_matop.c
+++ b/src/seq_mv/csr_matop.c
@@ -1832,7 +1832,7 @@ hypre_CSRMatrixFnorm( hypre_CSRMatrix *A )
  *         2, square sum
  *--------------------------------------------------------------------------*/
 
-void
+HYPRE_Int
 hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A,
                                   HYPRE_Int       *CF_i,
                                   HYPRE_Int       *CF_j,
@@ -1875,13 +1875,15 @@ hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A,
 
       row_sum[i] = row_sum_i;
    }
+
+   return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
  * hypre_CSRMatrixComputeRowSum
  *--------------------------------------------------------------------------*/
 
-void
+HYPRE_Int
 hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A,
                               HYPRE_Int       *CF_i,
                               HYPRE_Int       *CF_j,
@@ -1904,6 +1906,152 @@ hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A,
    {
       hypre_CSRMatrixComputeRowSumHost(A, CF_i, CF_j, row_sum, type, scal, set_or_add);
    }
+
+   return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ * Computes the column sums of a matrix.
+ * Assumes the input vector col_sum has size num_cols and equal to zeroes.
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSumHost( hypre_CSRMatrix *A,
+                                  HYPRE_Complex   *col_sum,
+                                  HYPRE_Int        type,
+                                  HYPRE_Complex    scal)
+{
+   HYPRE_Int      num_rows = hypre_CSRMatrixNumRows(A);
+   HYPRE_Int      num_cols = hypre_CSRMatrixNumCols(A);
+   HYPRE_Int     *rownnz   = hypre_CSRMatrixRownnz(A);
+   HYPRE_Complex *A_data   = hypre_CSRMatrixData(A);
+   HYPRE_Int     *A_i      = hypre_CSRMatrixI(A);
+   HYPRE_Int     *A_j      = hypre_CSRMatrixJ(A);
+
+#ifdef HYPRE_USING_OPENMP
+   #pragma omp parallel
+#endif
+   {
+      HYPRE_Int      tid = hypre_GetThreadNum();
+      HYPRE_Int      num_threads = hypre_NumActiveThreads();
+      HYPRE_Int      i, ii, j, col, ns, ne;
+      HYPRE_Complex *work;
+
+      /* Compute rows partitioning */
+      hypre_partition1D(num_rows, num_threads, tid, &ns, &ne);
+
+      /* Allocate work data */
+      work = (num_threads == 1) ?
+             col_sum : hypre_CTAlloc(HYPRE_Complex, num_cols, HYPRE_MEMORY_HOST);
+
+      switch (type)
+      {
+         case 0:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * A_data[j];
+               }
+            }
+            break;
+         }
+
+         case 1:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * hypre_cabs(A_data[j]);
+               }
+            }
+            break;
+         }
+
+         case 2:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * A_data[j] * A_data[j];
+               }
+            }
+            break;
+         }
+      }
+
+      /* Reduce results */
+      if (num_threads > 1)
+      {
+         for (i = 0; i < num_threads; i++)
+         {
+            if (i == tid)
+            {
+               for (j = 0; j < num_cols; j++)
+               {
+                  col_sum[j] = work[j];
+               }
+            }
+#ifdef HYPRE_USING_OPENMP
+            #pragma omp barrier
+#endif
+         }
+
+         hypre_TFree(work, HYPRE_MEMORY_HOST);
+      }
+   }
+
+   return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A,
+                              HYPRE_Complex   *col_sum,
+                              HYPRE_Int        type,
+                              HYPRE_Complex    scal)
+
+{
+   /* Trivial case */
+   if (!hypre_CSRMatrixNumCols(A))
+   {
+      return hypre_error_flag;
+   }
+
+#if defined(HYPRE_USING_GPU)
+   HYPRE_ExecutionPolicy exec = hypre_GetExecPolicy1( hypre_CSRMatrixMemoryLocation(A) );
+
+   if (exec == HYPRE_EXEC_DEVICE)
+   {
+      hypre_CSRMatrixComputeColSumDevice(A, col_sum, type, scal);
+   }
+   else
+#endif
+   {
+      hypre_CSRMatrixComputeColSumHost(A, col_sum, type, scal);
+   }
+
+   return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
@@ -2214,6 +2362,7 @@ hypre_CSRMatrixSetConstantValues( hypre_CSRMatrix *A,
 
 /*--------------------------------------------------------------------------
  * Computes the Frobenius norm for each tag in a CSR matrix.
+ *
  * Each row is assigned a tag (block identifier) via the tags array (local rows only).
  * The result is stored in the output pointer tnorms_ptr (length num_tags * num_tags).
  *--------------------------------------------------------------------------*/
@@ -2222,7 +2371,7 @@ HYPRE_Int
 hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
                                HYPRE_Int         num_tags,
                                HYPRE_Int        *tags,
-                               HYPRE_Real      **tnorms_ptr)
+                               HYPRE_Real       *tnorms)
 {
    HYPRE_Int       *A_i         = hypre_CSRMatrixI(A);
    HYPRE_Int       *A_j         = hypre_CSRMatrixJ(A);
@@ -2232,27 +2381,6 @@ hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
    HYPRE_Int        tnorms_size = num_tags * num_tags;
    HYPRE_Int        i, j, itag, jtag;
 
-   /* Create tnorms array */
-   if (!*tnorms_ptr)
-   {
-      *tnorms_ptr = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_HOST);
-   }
-   else
-   {
-      /* Initialize tnorms array */
-      for (i = 0; i < tnorms_size; i++)
-      {
-         (*tnorms_ptr)[i] = 0.0;
-      }
-   }
-
-   /* Call regular Frobenius norm if no tags or only one tag */
-   if (num_tags <= 1 || !tags)
-   {
-      (*tnorms_ptr)[0] = hypre_CSRMatrixFnorm(A);
-      return hypre_error_flag;
-   }
-
    /* Accumulate sums */
    for (i = 0; i < num_rows; i++)
    {
@@ -2263,43 +2391,64 @@ hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
       {
          jtag = tags[A_j[j]];
          hypre_assert(jtag >= 0 && jtag < num_tags);
-         (*tnorms_ptr)[itag * num_tags + jtag] += hypre_squared(A_a[j]);
+         tnorms[itag * num_tags + jtag] += hypre_squared(A_a[j]);
       }
    }
 
    /* Take square root for each block */
    for (i = 0; i < tnorms_size; i++)
    {
-      (*tnorms_ptr)[i] = hypre_sqrt((*tnorms_ptr)[i]);
+      tnorms[i] = hypre_sqrt(tnorms[i]);
    }
 
    return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
- * hypre_CSRMatrixTaggedFnorm
+ * Compute tagged Frobenius norms of an input matrix
  *--------------------------------------------------------------------------*/
 
 HYPRE_Int
-hypre_CSRMatrixTaggedFnorm(hypre_CSRMatrix *A,
-                           HYPRE_Int        num_tags,
-                           HYPRE_Int       *tags,
+hypre_CSRMatrixTaggedFnorm(hypre_CSRMatrix  *A,
+                           HYPRE_Int         num_tags,
+                           HYPRE_Int        *tags,
                            HYPRE_Real      **tnorms_ptr)
 {
+   HYPRE_Int     tnorms_size = num_tags * num_tags;
+   HYPRE_Int     i;
+
+   /* Create tnorms array */
+   if (!*tnorms_ptr)
+   {
+      *tnorms_ptr = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_HOST);
+   }
+   else
+   {
+      /* Initialize tnorms array */
+      for (i = 0; i < tnorms_size; i++)
+      {
+         (*tnorms_ptr)[i] = 0.0;
+      }
+   }
+
+   /* Call regular Frobenius norm if no tags or only one tag */
+   if (num_tags <= 1 || !tags)
+   {
+      (*tnorms_ptr)[0] = hypre_CSRMatrixFnorm(A);
+      return hypre_error_flag;
+   }
+
 #if defined(HYPRE_USING_GPU)
    HYPRE_MemoryLocation memory_location = hypre_CSRMatrixMemoryLocation(A);
 
    if (hypre_GetExecPolicy1(memory_location) == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): hypre_ParCSRMatrixTaggedFnormDevice */
-      hypre_CSRMatrixMigrate(A, HYPRE_MEMORY_HOST);
-      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, tnorms_ptr);
-      hypre_CSRMatrixMigrate(A, HYPRE_MEMORY_DEVICE);
+      hypre_CSRMatrixTaggedFnormDevice(A, num_tags, tags, *tnorms_ptr);
    }
    else
 #endif
    {
-      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, tnorms_ptr);
+      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, *tnorms_ptr);
    }
 
    return hypre_error_flag;
diff --git a/src/seq_mv/csr_matop_device.c b/src/seq_mv/csr_matop_device.c
index c5ad8ece1..10e44c122 100644
--- a/src/seq_mv/csr_matop_device.c
+++ b/src/seq_mv/csr_matop_device.c
@@ -1327,6 +1327,255 @@ hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ * GPU kernel for computing the column sums of a CSR matrix.
+ *
+ * Each warp processes one row and accumulates into shared memory.
+ *--------------------------------------------------------------------------*/
+
+template <HYPRE_Int type>
+__global__ void
+hypreGPUKernel_CSRMatrixComputeColSum(hypre_DeviceItem    &item,
+                                      HYPRE_Int            nrows,
+                                      HYPRE_Int            ncols,
+                                      const HYPRE_Int     *ia,
+                                      const HYPRE_Int     *ja,
+                                      const HYPRE_Complex *aa,
+                                      const HYPRE_Complex  scal,
+                                      HYPRE_Complex       *col_sum)
+{
+   /* Get warp and lane IDs */
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int num_warps = item.get_group(2) / HYPRE_WARP_SIZE;
+#else
+   const HYPRE_Int num_warps = blockDim.x / HYPRE_WARP_SIZE;
+#endif
+   const HYPRE_Int warp_id = hypre_gpu_get_warp_id<1>(item);
+   const HYPRE_Int lane_id = hypre_gpu_get_lane_id<1>(item);
+   const HYPRE_Int warp_in_block = warp_id % num_warps;
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int row = item.get_group(2) * num_warps + warp_in_block;
+#else
+   const HYPRE_Int row = blockIdx.x * num_warps + warp_in_block;
+#endif
+
+   if (row < nrows)
+   {
+      /* Load row bounds using warp shuffle */
+      HYPRE_Int p = 0, q = 0;
+      if (lane_id < 2)
+      {
+         p = read_only_load(ia + row + lane_id);
+      }
+      q = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 1);
+      p = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 0);
+
+      /* Process row elements using warp-level parallelism */
+      for (HYPRE_Int j = p + lane_id; j < q; j += HYPRE_WARP_SIZE)
+      {
+         HYPRE_Int     col = read_only_load(ja + j);
+         HYPRE_Complex val = read_only_load(aa + j);
+         HYPRE_Complex colsum = 0.0;
+
+         if (type == 0)
+         {
+            colsum = scal * val;
+         }
+         else if (type == 1)
+         {
+            colsum = scal * hypre_abs(val);
+         }
+         else if (type == 2)
+         {
+            colsum = scal * val * val;
+         }
+
+         /* Atomic add is required to prevent race conditions, as multiple warps
+           (processing different rows) may update the same column sum simultaneously. */
+         hypre_gpu_atomicAdd(col, col_sum, colsum);
+      }
+   }
+}
+
+/*--------------------------------------------------------------------------
+ * Computes column-wise sum of a CSR matrix on the device.
+ *
+ * type == 0, sum
+ *         1, abs sum (L1-norm)
+ *         2, square sum (L2-norm squared)
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSumDevice(hypre_CSRMatrix  *A,
+                                   HYPRE_Complex    *col_sum,
+                                   HYPRE_Int         type,
+                                   HYPRE_Complex     scal)
+{
+    HYPRE_Int       nrows = hypre_CSRMatrixNumRows(A);
+    HYPRE_Int       ncols = hypre_CSRMatrixNumCols(A);
+    HYPRE_Int      *A_i   = hypre_CSRMatrixI(A);
+    HYPRE_Int      *A_j   = hypre_CSRMatrixJ(A);
+    HYPRE_Complex  *A_a   = hypre_CSRMatrixData(A);
+
+    /* Use standard block dimensions */
+    dim3 bDim = hypre_GetDefaultDeviceBlockDimension();
+    dim3 gDim = hypre_GetDefaultDeviceGridDimension(nrows, "warp", bDim);
+
+    /* Launch kernel based on type */
+    if (type == 0)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<0>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+    else if (type == 1)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<1>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+    else if (type == 2)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<2>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+
+    hypre_SyncComputeStream();
+
+    return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+__global__ void
+hypreGPUKernel_CSRMatrixTaggedFnormAccum(hypre_DeviceItem    &item,
+#if defined (HYPRE_USING_SYCL)
+                                         char                *shmem_ptr,
+#endif
+                                         const HYPRE_Int      nrows,
+                                         const HYPRE_Int      num_tags,
+                                         const HYPRE_Int     *tags,
+                                         const HYPRE_Int     *ia,
+                                         const HYPRE_Int     *ja,
+                                         const HYPRE_Complex *aa,
+                                         HYPRE_Real          *tnorms)
+{
+   /* Get warp and lane IDs */
+   const HYPRE_Int  num_warps     = hypre_gpu_get_blockDim<0>(item) / HYPRE_WARP_SIZE;
+   const HYPRE_Int  warp_id       = hypre_gpu_get_warp_id<1>(item);
+   const HYPRE_Int  lane_id       = hypre_gpu_get_lane_id<1>(item);
+   const HYPRE_Int  warp_in_block = warp_id % num_warps;
+   const HYPRE_Int  row           = hypre_gpu_get_blockDim<0>(item) * num_warps + warp_in_block;
+   const HYPRE_Int  itag          = tags[row];
+
+   /* Shared memory */
+#if defined (HYPRE_USING_SYCL)
+   HYPRE_Real      *sdata         = (HYPRE_Real*) & (shmem_ptr[0]);
+#else
+   extern __shared__ HYPRE_Real shmem[];
+   HYPRE_Real      *sdata         = shmem;
+#endif
+
+   /* Initialize shared memory */
+   for (HYPRE_Int i = hypre_gpu_get_threadIdx<0>(item);
+        i < num_tags * num_tags;
+        i += hypre_gpu_get_blockDim<0>(item))
+   {
+      sdata[i] = 0.0;
+   }
+   block_sync(item);
+
+   if (row < nrows)
+   {
+      /* Load row bounds using warp shuffle */
+      HYPRE_Int p = 0, q = 0;
+      if (lane_id < 2)
+      {
+         p = read_only_load(ia + row + lane_id);
+      }
+      q = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 1);
+      p = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 0);
+
+      /* Process row elements using warp-level parallelism */
+      for (HYPRE_Int j = p + lane_id; j < q; j += HYPRE_WARP_SIZE)
+      {
+         HYPRE_Int       col  = read_only_load(ja + j);
+         HYPRE_Int       jtag = tags[col];
+         HYPRE_Complex   val  = read_only_load(aa + j);
+         const HYPRE_Int idx  = itag * num_tags + jtag;
+
+         /* Two threads in the same warp might add to the same position,
+            therefore we need to use atomic add */
+         hypre_gpu_atomicAdd(idx, sdata, hypre_squared(val));
+      }
+   }
+   block_sync(item);
+
+   /* Final reduction from shared memory to global memory */
+   if (hypre_gpu_get_threadIdx<0>(item) == 0)
+   {
+      for (HYPRE_Int i = 0; i < num_tags * num_tags; i++)
+      {
+         hypre_gpu_atomicAdd(i, tnorms, sdata[i]);
+      }
+   }
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix  *A,
+                                 HYPRE_Int         num_tags,
+                                 HYPRE_Int        *tags,
+                                 HYPRE_Real       *tnorms)
+{
+   HYPRE_Int       num_rows    = hypre_CSRMatrixNumRows(A);
+   HYPRE_Int      *A_i         = hypre_CSRMatrixI(A);
+   HYPRE_Int      *A_j         = hypre_CSRMatrixJ(A);
+   HYPRE_Complex  *A_a         = hypre_CSRMatrixData(A);
+
+   HYPRE_Int       tnorms_size = num_tags * num_tags;
+   HYPRE_Int       i;
+   HYPRE_Real     *d_tnorms;
+
+   /* Sanity check */
+   if (num_tags > 64)
+   {
+      hypre_error_w_msg(HYPRE_ERROR_GENERIC, "Too many tags for shared memory kernel (max is 64)");
+      return hypre_error_flag;
+   }
+
+   HYPRE_ANNOTATE_FUNC_BEGIN;
+   hypre_GpuProfilingPushRange("CSRMatrixTaggedFnorm");
+
+   /* Allocate device buffers */
+   d_tnorms = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_DEVICE);
+
+   /* Launch accumulation kernel */
+   dim3 bDim = hypre_GetDefaultDeviceBlockDimension();
+   dim3 gDim = hypre_GetDefaultDeviceGridDimension(num_rows, "warp", bDim);
+   const size_t shmem_bytes = tnorms_size * sizeof(HYPRE_Complex);
+
+   HYPRE_GPU_LAUNCH2(hypreGPUKernel_CSRMatrixTaggedFnormAccum, gDim, bDim, shmem_bytes,
+                     num_rows, num_tags, tags, A_i, A_j, A_a, d_tnorms);
+
+   /* Copy back to host and free device buffer */
+   hypre_TMemcpy(tnorms, d_tnorms, HYPRE_Real, tnorms_size,
+                 HYPRE_MEMORY_HOST, HYPRE_MEMORY_DEVICE);
+   hypre_TFree(d_tnorms, HYPRE_MEMORY_DEVICE);
+
+   /* Take square root for each block */
+   for (i = 0; i < tnorms_size; i++)
+   {
+      tnorms[i] = hypre_sqrt(tnorms[i]);
+   }
+
+   hypre_GpuProfilingPopRange();
+   HYPRE_ANNOTATE_FUNC_END;
+
+   return hypre_error_flag;
+}
+
 /*--------------------------------------------------------------------------
  * hypreGPUKernel_CSRMatrixIntersectPattern
  *
diff --git a/src/seq_mv/protos.h b/src/seq_mv/protos.h
index 42ec225a3..09eb9de56 100644
--- a/src/seq_mv/protos.h
+++ b/src/seq_mv/protos.h
@@ -40,10 +40,11 @@ HYPRE_Int hypre_CSRMatrixSplit(hypre_CSRMatrix *Bs_ext, HYPRE_BigInt first_col_d
                                hypre_CSRMatrix **Bext_offd_ptr);
 hypre_CSRMatrix * hypre_CSRMatrixAddPartial( hypre_CSRMatrix *A, hypre_CSRMatrix *B,
                                              HYPRE_Int *row_nums);
-void hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                       HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
-void hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                   HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
+HYPRE_Int hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
+                                        HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal,
+                                        const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A, HYPRE_Complex *col_sum,
+                                        HYPRE_Int type, HYPRE_Complex scal );
 HYPRE_Int hypre_CSRMatrixExtractDiagonal( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalHost( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixScale(hypre_CSRMatrix *A, HYPRE_Complex scalar);
@@ -86,6 +87,10 @@ HYPRE_Int hypre_CSRMatrixReplaceDiagDevice( hypre_CSRMatrix *A, HYPRE_Complex *n
 HYPRE_Int hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
                                               HYPRE_Complex *row_sum, HYPRE_Int type,
                                               HYPRE_Complex scal, const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSumDevice( hypre_CSRMatrix *A,  HYPRE_Complex *col_sum,
+                                              HYPRE_Int type, HYPRE_Complex scal );
+HYPRE_Int hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix *A, HYPRE_Int num_tags,
+                                           HYPRE_Int *tags, HYPRE_Real *tnorms);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalDevice( hypre_CSRMatrix *A, HYPRE_Complex *d,
                                                 HYPRE_Int type );
 hypre_CSRMatrix* hypre_CSRMatrixStack2Device(hypre_CSRMatrix *A, hypre_CSRMatrix *B);
@@ -269,6 +274,7 @@ HYPRE_Int hypre_SeqVectorSetNumTags( hypre_Vector *vector, HYPRE_Int num_tags );
 HYPRE_Int hypre_SeqVectorSetTags( hypre_Vector *vector,
                                   HYPRE_MemoryLocation memory_location,
                                   HYPRE_Int *tags );
+HYPRE_Int hypre_SeqVectorSetValuesTagged( hypre_Vector *vector, HYPRE_Complex *values );
 HYPRE_Int hypre_SeqVectorInitialize_v2( hypre_Vector *vector,
                                         HYPRE_MemoryLocation memory_location );
 HYPRE_Int hypre_SeqVectorInitialize ( hypre_Vector *vector );
@@ -385,6 +391,7 @@ HYPRE_Int hypre_CSRMatrixSpMVAnalysisDevice(hypre_CSRMatrix *matrix);
 
 /* vector_device.c */
 HYPRE_Int hypre_SeqVectorSetConstantValuesDevice ( hypre_Vector *v, HYPRE_Complex value );
+HYPRE_Int hypre_SeqVectorSetValuesTaggedDevice( hypre_Vector *vector, HYPRE_Complex *values );
 HYPRE_Int hypre_SeqVectorScaleDevice( HYPRE_Complex alpha, hypre_Vector *y );
 HYPRE_Int hypre_SeqVectorAxpyDevice ( HYPRE_Complex alpha, hypre_Vector *x, hypre_Vector *y );
 HYPRE_Int hypre_SeqVectorAxpyzDevice ( HYPRE_Complex alpha, hypre_Vector *x,
diff --git a/src/seq_mv/seq_mv.h b/src/seq_mv/seq_mv.h
index c262e0ab0..7b4c59c1b 100644
--- a/src/seq_mv/seq_mv.h
+++ b/src/seq_mv/seq_mv.h
@@ -324,10 +324,11 @@ HYPRE_Int hypre_CSRMatrixSplit(hypre_CSRMatrix *Bs_ext, HYPRE_BigInt first_col_d
                                hypre_CSRMatrix **Bext_offd_ptr);
 hypre_CSRMatrix * hypre_CSRMatrixAddPartial( hypre_CSRMatrix *A, hypre_CSRMatrix *B,
                                              HYPRE_Int *row_nums);
-void hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                       HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
-void hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                   HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
+HYPRE_Int hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
+                                        HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal,
+                                        const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A, HYPRE_Complex *col_sum,
+                                        HYPRE_Int type, HYPRE_Complex scal );
 HYPRE_Int hypre_CSRMatrixExtractDiagonal( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalHost( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixScale(hypre_CSRMatrix *A, HYPRE_Complex scalar);
@@ -370,6 +371,10 @@ HYPRE_Int hypre_CSRMatrixReplaceDiagDevice( hypre_CSRMatrix *A, HYPRE_Complex *n
 HYPRE_Int hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
                                               HYPRE_Complex *row_sum, HYPRE_Int type,
                                               HYPRE_Complex scal, const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSumDevice( hypre_CSRMatrix *A,  HYPRE_Complex *col_sum,
+                                              HYPRE_Int type, HYPRE_Complex scal );
+HYPRE_Int hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix *A, HYPRE_Int num_tags,
+                                           HYPRE_Int *tags, HYPRE_Real *tnorms);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalDevice( hypre_CSRMatrix *A, HYPRE_Complex *d,
                                                 HYPRE_Int type );
 hypre_CSRMatrix* hypre_CSRMatrixStack2Device(hypre_CSRMatrix *A, hypre_CSRMatrix *B);
@@ -553,6 +558,7 @@ HYPRE_Int hypre_SeqVectorSetNumTags( hypre_Vector *vector, HYPRE_Int num_tags );
 HYPRE_Int hypre_SeqVectorSetTags( hypre_Vector *vector,
                                   HYPRE_MemoryLocation memory_location,
                                   HYPRE_Int *tags );
+HYPRE_Int hypre_SeqVectorSetValuesTagged( hypre_Vector *vector, HYPRE_Complex *values );
 HYPRE_Int hypre_SeqVectorInitialize_v2( hypre_Vector *vector,
                                         HYPRE_MemoryLocation memory_location );
 HYPRE_Int hypre_SeqVectorInitialize ( hypre_Vector *vector );
@@ -669,6 +675,7 @@ HYPRE_Int hypre_CSRMatrixSpMVAnalysisDevice(hypre_CSRMatrix *matrix);
 
 /* vector_device.c */
 HYPRE_Int hypre_SeqVectorSetConstantValuesDevice ( hypre_Vector *v, HYPRE_Complex value );
+HYPRE_Int hypre_SeqVectorSetValuesTaggedDevice( hypre_Vector *vector, HYPRE_Complex *values );
 HYPRE_Int hypre_SeqVectorScaleDevice( HYPRE_Complex alpha, hypre_Vector *y );
 HYPRE_Int hypre_SeqVectorAxpyDevice ( HYPRE_Complex alpha, hypre_Vector *x, hypre_Vector *y );
 HYPRE_Int hypre_SeqVectorAxpyzDevice ( HYPRE_Complex alpha, hypre_Vector *x,
diff --git a/src/seq_mv/vector.c b/src/seq_mv/vector.c
index cf3a07147..a9accaa90 100644
--- a/src/seq_mv/vector.c
+++ b/src/seq_mv/vector.c
@@ -219,6 +219,65 @@ hypre_SeqVectorSetTags( hypre_Vector          *vector,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_SeqVectorSetValuesTaggedHost( hypre_Vector  *vector,
+                                    HYPRE_Complex *values )
+{
+   HYPRE_Int   size = hypre_VectorSize(vector);
+   HYPRE_Int  *tags = hypre_VectorTags(vector);
+   HYPRE_Int   i;
+
+   /* Setup scaling vector */
+#if defined(HYPRE_USING_OPENMP)
+   #pragma omp parallel for private(i) HYPRE_SMP_SCHEDULE
+#endif
+   for (i = 0; i < size; i++)
+   {
+      hypre_VectorEntryI(vector, i) = values[tags[i]];
+   }
+
+   return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_SeqVectorSetValuesTagged( hypre_Vector  *vector,
+                                HYPRE_Complex *values )
+{
+   /* Sanity checks */
+   if (hypre_VectorNumVectors(vector) > 1)
+   {
+      hypre_error_w_msg(HYPRE_ERROR_GENERIC, "num_vectors > 1 not implemented!");
+      return hypre_error_flag;
+   }
+
+   if (!hypre_VectorTags(vector) || hypre_VectorNumTags(vector) < 2)
+   {
+      hypre_error_w_msg(HYPRE_ERROR_GENERIC, "This function is valid only for multi-tagged vectors");
+      return hypre_error_flag;
+   }
+
+#if defined(HYPRE_USING_GPU) || defined(HYPRE_USING_DEVICE_OPENMP)
+   HYPRE_ExecutionPolicy exec = hypre_GetExecPolicy1(hypre_VectorMemoryLocation(vector));
+
+   if (exec == HYPRE_EXEC_DEVICE)
+   {
+      hypre_SeqVectorSetValuesTaggedDevice(vector, values);
+   }
+   else
+#endif
+   {
+      hypre_SeqVectorSetValuesTaggedHost(vector, values);
+   }
+
+   return hypre_error_flag;
+}
+
 /*--------------------------------------------------------------------------
  * hypre_SeqVectorInitialize_v2
  *
diff --git a/src/seq_mv/vector_device.c b/src/seq_mv/vector_device.c
index 09e47d8d7..d78f6b2ca 100644
--- a/src/seq_mv/vector_device.c
+++ b/src/seq_mv/vector_device.c
@@ -51,6 +51,32 @@ hypre_SeqVectorSetConstantValuesDevice( hypre_Vector *v,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_SeqVectorSetValuesTaggedDevice( hypre_Vector  *vector,
+                                      HYPRE_Complex *values )
+{
+   HYPRE_Int      size = hypre_VectorSize(vector);
+   HYPRE_Int     *tags = hypre_VectorTags(vector);
+   HYPRE_Complex *data = hypre_VectorData(vector);
+
+#if defined(HYPRE_USING_CUDA) || defined(HYPRE_USING_HIP)
+   HYPRE_THRUST_CALL(gather, tags, tags + size, values, data);
+
+#elif defined(HYPRE_USING_SYCL)
+   hypreSycl_gather(tags, tags + size, values, data);
+
+#elif defined(HYPRE_USING_DEVICE_OPENMP)
+   hypre_error_w_msg(HYPRE_ERROR_GENERIC, "Device OpenMP not implemented!");
+#endif
+
+   hypre_SyncComputeStream();
+
+   return hypre_error_flag;
+}
+
 /*--------------------------------------------------------------------------
  * hypre_SeqVectorScaleDevice
  *--------------------------------------------------------------------------*/
diff --git a/src/utilities/_hypre_utilities.hpp b/src/utilities/_hypre_utilities.hpp
index 9fc8d5acf..234efdc43 100644
--- a/src/utilities/_hypre_utilities.hpp
+++ b/src/utilities/_hypre_utilities.hpp
@@ -1151,6 +1151,42 @@ hypre_mask hypre_mask_flip_at(hypre_mask bitmask, hypre_int n)
 
 #if defined(HYPRE_USING_CUDA) || defined(HYPRE_USING_HIP)
 
+/* return the thread identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_threadIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return threadIdx.x;
+   if constexpr (dim == 1) return threadIdx.y;
+   if constexpr (dim == 2) return threadIdx.z;
+
+   return -1;
+}
+
+/* return the block identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return blockIdx.x;
+   if constexpr (dim == 1) return blockIdx.y;
+   if constexpr (dim == 2) return blockIdx.z;
+
+   return -1;
+}
+
+/* return the block dimension in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockDim(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return blockDim.x;
+   if constexpr (dim == 1) return blockDim.y;
+   if constexpr (dim == 2) return blockDim.z;
+
+   return -1;
+}
+
 /* return the number of threads in block */
 template <hypre_int dim>
 static __device__ __forceinline__
@@ -1305,6 +1341,14 @@ hypre_double atomicAdd(hypre_double* address, hypre_double val)
 }
 #endif
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   atomicAdd((T*)(address + pos), val);
+}
+
 // There are no *_sync functions in HIP
 #if defined(HYPRE_USING_HIP) || (CUDA_VERSION < 9000)
 
@@ -1755,6 +1799,42 @@ struct print_functor
 
 #if defined(HYPRE_USING_SYCL)
 
+/* return the thread identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_threadIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_local_id(2);
+   if constexpr (dim == 1) return item.get_local_id(1);
+   if constexpr (dim == 2) return item.get_local_id(0);
+
+   return -1;
+}
+
+/* return the block identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_group(2);
+   if constexpr (dim == 1) return item.get_group(1);
+   if constexpr (dim == 2) return item.get_group(0);
+
+   return -1;
+}
+
+/* return the block dimension in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockDim(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_local_range(2);
+   if constexpr (dim == 1) return item.get_local_range(1);
+   if constexpr (dim == 2) return item.get_local_range(0);
+
+   return -1;
+}
+
 /* return the number of threads in block */
 template <hypre_int dim>
 static __device__ __forceinline__
@@ -1845,6 +1925,19 @@ hypre_int hypre_gpu_get_grid_warp_id(hypre_DeviceItem &item)
           hypre_gpu_get_warp_id<bdim>(item);
 }
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   auto atomic_val = sycl::atomic_ref<T,
+                                      sycl::memory_order::relaxed,
+                                      sycl::memory_scope::device,
+                                      sycl::access::address_space::local_space > (address[pos]);
+   auto curr = atomic_val.load(sycl::memory_order::relaxed);
+   while (!atomic_val.compare_exchange_strong(curr, curr + val, sycl::memory_order::relaxed)) {}
+}
+
 /* sync the thread block */
 static __device__ __forceinline__
 void block_sync(hypre_DeviceItem &item)
diff --git a/src/utilities/device_utils.h b/src/utilities/device_utils.h
index b4a494767..91c26adca 100644
--- a/src/utilities/device_utils.h
+++ b/src/utilities/device_utils.h
@@ -955,6 +955,42 @@ hypre_mask hypre_mask_flip_at(hypre_mask bitmask, hypre_int n)
 
 #if defined(HYPRE_USING_CUDA) || defined(HYPRE_USING_HIP)
 
+/* return the thread identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_threadIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return threadIdx.x;
+   if constexpr (dim == 1) return threadIdx.y;
+   if constexpr (dim == 2) return threadIdx.z;
+
+   return -1;
+}
+
+/* return the block identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return blockIdx.x;
+   if constexpr (dim == 1) return blockIdx.y;
+   if constexpr (dim == 2) return blockIdx.z;
+
+   return -1;
+}
+
+/* return the block dimension in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockDim(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return blockDim.x;
+   if constexpr (dim == 1) return blockDim.y;
+   if constexpr (dim == 2) return blockDim.z;
+
+   return -1;
+}
+
 /* return the number of threads in block */
 template <hypre_int dim>
 static __device__ __forceinline__
@@ -1109,6 +1145,14 @@ hypre_double atomicAdd(hypre_double* address, hypre_double val)
 }
 #endif
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   atomicAdd((T*)(address + pos), val);
+}
+
 // There are no *_sync functions in HIP
 #if defined(HYPRE_USING_HIP) || (CUDA_VERSION < 9000)
 
@@ -1559,6 +1603,42 @@ struct print_functor
 
 #if defined(HYPRE_USING_SYCL)
 
+/* return the thread identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_threadIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_local_id(2);
+   if constexpr (dim == 1) return item.get_local_id(1);
+   if constexpr (dim == 2) return item.get_local_id(0);
+
+   return -1;
+}
+
+/* return the block identifier in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockIdx(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_group(2);
+   if constexpr (dim == 1) return item.get_group(1);
+   if constexpr (dim == 2) return item.get_group(0);
+
+   return -1;
+}
+
+/* return the block dimension in direction dim */
+template <hypre_int dim>
+static __device__ __forceinline__
+hypre_int hypre_gpu_get_blockDim(hypre_DeviceItem &item)
+{
+   if constexpr (dim == 0) return item.get_local_range(2);
+   if constexpr (dim == 1) return item.get_local_range(1);
+   if constexpr (dim == 2) return item.get_local_range(0);
+
+   return -1;
+}
+
 /* return the number of threads in block */
 template <hypre_int dim>
 static __device__ __forceinline__
@@ -1649,6 +1729,19 @@ hypre_int hypre_gpu_get_grid_warp_id(hypre_DeviceItem &item)
           hypre_gpu_get_warp_id<bdim>(item);
 }
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   auto atomic_val = sycl::atomic_ref<T,
+                                      sycl::memory_order::relaxed,
+                                      sycl::memory_scope::device,
+                                      sycl::access::address_space::local_space > (address[pos]);
+   auto curr = atomic_val.load(sycl::memory_order::relaxed);
+   while (!atomic_val.compare_exchange_strong(curr, curr + val, sycl::memory_order::relaxed)) {}
+}
+
 /* sync the thread block */
 static __device__ __forceinline__
 void block_sync(hypre_DeviceItem &item)
diff --git a/src/utilities/memory_tracker.c b/src/utilities/memory_tracker.c
index 895611e3d..c3f9385ea 100644
--- a/src/utilities/memory_tracker.c
+++ b/src/utilities/memory_tracker.c
@@ -110,7 +110,7 @@ hypre_MemoryTrackerQueueCompSearch(const void *e1,
 hypre_MemoryTrackerEvent
 hypre_MemoryTrackerGetNext(hypre_MemoryTracker *tracker)
 {
-   hypre_MemoryTrackerEvent i, k = HYPRE_MEMORY_NUM_EVENTS;
+   HYPRE_Int                 i, k = HYPRE_MEMORY_NUM_EVENTS;
    hypre_MemoryTrackerQueue *q = tracker->queue;
 
    for (i = HYPRE_MEMORY_EVENT_ALLOC; i < HYPRE_MEMORY_NUM_EVENTS; i++)
@@ -126,7 +126,7 @@ hypre_MemoryTrackerGetNext(hypre_MemoryTracker *tracker)
       }
    }
 
-   return k;
+   return (hypre_MemoryTrackerEvent) k;
 }
 
 HYPRE_Int
@@ -330,7 +330,7 @@ hypre_PrintMemoryTracker( size_t     *totl_bytes_o,
    size_t curr_bytes[hypre_NUM_MEMORY_LOCATION] = {0};
    size_t copy_bytes[hypre_MEMCPY_NUM_TYPES] = {0};
    size_t j;
-   hypre_MemoryTrackerEvent i;
+   HYPRE_Int i;
    //HYPRE_Real t0 = hypre_MPI_Wtime();
 
    HYPRE_Int leakcheck = 1;
@@ -404,11 +404,12 @@ hypre_PrintMemoryTracker( size_t     *totl_bytes_o,
             hypre_MemoryTrackerEntry key = { .ptr = entry->ptr };
             hypre_MemoryTrackerEntry *key_ptr = &key;
 
-            hypre_MemoryTrackerEntry **result = bsearch(&key_ptr,
-                                                        qf->sorted_data_compressed,
-                                                        qf->sorted_data_compressed_len,
-                                                        sizeof(hypre_MemoryTrackerEntry *),
-                                                        hypre_MemoryTrackerQueueCompSearch);
+            hypre_MemoryTrackerEntry **result = (hypre_MemoryTrackerEntry **)
+                                                   bsearch(&key_ptr,
+                                                           qf->sorted_data_compressed,
+                                                           qf->sorted_data_compressed_len,
+                                                           sizeof(hypre_MemoryTrackerEntry *),
+                                                           hypre_MemoryTrackerQueueCompSearch);
             if (result)
             {
                j = result - qf->sorted_data_compressed;
@@ -608,14 +609,14 @@ hypre_PrintMemoryTracker( size_t     *totl_bytes_o,
 
    if (leakcheck)
    {
-      hypre_MemoryLocation t;
+      HYPRE_Int t;
 
       for (t = hypre_MEMORY_HOST; t <= hypre_MEMORY_UNIFIED; t++)
       {
          if (curr_bytes[t])
          {
             char memory_location[256];
-            hypre_GetMemoryLocationName(t, memory_location);
+            hypre_GetMemoryLocationName((hypre_MemoryLocation) t, memory_location);
             fprintf(stderr, "%zu bytes of %s memory may not be freed\n", curr_bytes[t], memory_location);
          }
 
diff --git a/src/utilities/nvtx.c b/src/utilities/nvtx.c
index 0b06f9669..7bae7a4e0 100644
--- a/src/utilities/nvtx.c
+++ b/src/utilities/nvtx.c
@@ -6,6 +6,7 @@
  ******************************************************************************/
 
 #include "_hypre_utilities.h"
+#include "_hypre_utilities.hpp"
 
 #if defined(HYPRE_USING_ROCTX)
 #include "hip/hip_runtime_api.h"
@@ -118,13 +119,13 @@ void hypre_GpuProfilingPopRange(void)
 {
 #if defined (HYPRE_USING_NVTX)
    hypre_GpuProfilingPushRangeColor("StreamSync0", Red);
-   cudaStreamSynchronize(0);
+   HYPRE_CUDA_CALL( cudaStreamSynchronize(0) );
    nvtxRangePop();
    nvtxRangePop();
 
 #elif defined (HYPRE_USING_ROCTX)
    roctxRangePush("StreamSync0");
-   hipStreamSynchronize(0);
+   HYPRE_HIP_CALL( hipStreamSynchronize(0) );
    roctxRangePop();
    roctxRangePop();
 #endif
