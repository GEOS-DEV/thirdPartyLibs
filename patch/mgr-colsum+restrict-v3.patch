diff --git a/src/parcsr_ls/_hypre_parcsr_ls.h b/src/parcsr_ls/_hypre_parcsr_ls.h
index 3c62f514f..ae8a0c591 100644
--- a/src/parcsr_ls/_hypre_parcsr_ls.h
+++ b/src/parcsr_ls/_hypre_parcsr_ls.h
@@ -3789,6 +3789,8 @@ HYPRE_Int hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix *A, HYPRE_
                                                    HYPRE_Int point_type, HYPRE_Int *CF_marker,
                                                    HYPRE_Int diag_type,
                                                    hypre_ParCSRMatrix **B_ptr );
+HYPRE_Int hypre_MGRBuildRFromWrDevice(hypre_IntArray *C_map, hypre_IntArray *F_map,
+                                      hypre_ParCSRMatrix *Wr, hypre_ParCSRMatrix *R);
 
 /* par_mgr_stats.c */
 HYPRE_Int hypre_MGRSetupStats( void *mgr_vdata );
diff --git a/src/parcsr_ls/par_mgr_device.c b/src/parcsr_ls/par_mgr_device.c
index 8c18b6255..9eafd7273 100644
--- a/src/parcsr_ls/par_mgr_device.c
+++ b/src/parcsr_ls/par_mgr_device.c
@@ -1004,4 +1004,119 @@ hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix  *A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ * Constructs a classical restriction operator as R = [Wr I] on GPU.
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_MGRBuildRFromWrDevice(hypre_IntArray      *C_map,
+                            hypre_IntArray      *F_map,
+                            hypre_ParCSRMatrix  *Wr,
+                            hypre_ParCSRMatrix  *R)
+{
+   /* Input matrix variables */
+   hypre_CSRMatrix       *Wr_diag          = hypre_ParCSRMatrixDiag(Wr);
+   HYPRE_Int             *Wr_diag_i        = hypre_CSRMatrixI(Wr_diag);
+   HYPRE_Int             *Wr_diag_j        = hypre_CSRMatrixJ(Wr_diag);
+   HYPRE_Complex         *Wr_diag_a        = hypre_CSRMatrixData(Wr_diag);
+   HYPRE_Int              Wr_diag_num_rows = hypre_CSRMatrixNumRows(Wr_diag);
+   HYPRE_Int             *C_map_data       = hypre_IntArrayData(C_map);
+   HYPRE_Int             *F_map_data       = hypre_IntArrayData(F_map);
+
+   /* Output matrix */
+   hypre_CSRMatrix       *R_diag           = hypre_ParCSRMatrixDiag(R);
+   HYPRE_Int             *R_diag_i         = hypre_CSRMatrixI(R_diag);
+   HYPRE_Int             *R_diag_j         = hypre_CSRMatrixJ(R_diag);
+   HYPRE_Complex         *R_diag_a         = hypre_CSRMatrixData(R_diag);
+
+   HYPRE_Int              nrows            = Wr_diag_num_rows;
+
+   /* 1. Compute row lengths: 1 (for I) + nnz in Wr row */
+   HYPRE_Int *row_lengths = hypre_TAlloc(HYPRE_Int, nrows, HYPRE_MEMORY_DEVICE);
+
+#if defined(HYPRE_USING_SYCL)
+   oneapi::dpl::counting_iterator<HYPRE_Int> row_begin(0);
+   HYPRE_ONEDPL_CALL(std::transform,
+                     row_begin, row_begin + nrows,
+                     row_lengths,
+                     [=](HYPRE_Int i) {
+                        return (1 + Wr_diag_i[i + 1] - Wr_diag_i[i]);
+                     });
+#else
+   HYPRE_THRUST_CALL(transform,
+                     thrust::make_counting_iterator<HYPRE_Int>(0),
+                     thrust::make_counting_iterator<HYPRE_Int>(nrows),
+                     row_lengths,
+                     [=] __device__ (HYPRE_Int i) {
+                        return (1 + Wr_diag_i[i + 1] - Wr_diag_i[i]);
+                     });
+#endif
+
+   /* 2. Inclusive scan to get R_diag_i */
+   HYPRE_Int zero = 0;
+   hypre_TMemcpy(R_diag_i, &zero, HYPRE_Int, 1, HYPRE_MEMORY_DEVICE, HYPRE_MEMORY_HOST);
+
+#if defined(HYPRE_USING_SYCL)
+   HYPRE_ONEDPL_CALL(std::inclusive_scan,
+                     row_lengths, row_lengths + nrows,
+                     R_diag_i + 1);
+#else
+   HYPRE_THRUST_CALL(inclusive_scan,
+                     row_lengths, row_lengths + nrows,
+                     R_diag_i + 1);
+#endif
+
+   // 3. Fill R_diag_j and R_diag_a in parallel, one row per thread
+#if defined(HYPRE_USING_SYCL)
+   HYPRE_ONEDPL_CALL(std::for_each,
+                     row_begin, row_begin + nrows,
+                     [=](HYPRE_Int i)
+   {
+      HYPRE_Int r_offset = R_diag_i[i];
+
+      /* I part */
+      R_diag_j[r_offset] = C_map_data[i];
+      R_diag_a[r_offset] = 1.0;
+      r_offset++;
+
+      /* Wr part */
+      for (HYPRE_Int jj = Wr_diag_i[i]; jj < Wr_diag_i[i+1]; jj++)
+      {
+         R_diag_j[r_offset] = F_map_data[Wr_diag_j[jj]];
+         R_diag_a[r_offset] = Wr_diag_a[jj];
+         r_offset++;
+      }
+   });
+#else
+   HYPRE_THRUST_CALL(for_each,
+                     thrust::make_counting_iterator<HYPRE_Int>(0),
+                     thrust::make_counting_iterator<HYPRE_Int>(nrows),
+                     [=] __device__ (HYPRE_Int i)
+   {
+      HYPRE_Int r_offset = R_diag_i[i];
+
+      /* I part */
+      R_diag_j[r_offset] = C_map_data[i];
+      R_diag_a[r_offset] = 1.0;
+      r_offset++;
+
+      /* Wr part */
+      for (HYPRE_Int jj = Wr_diag_i[i]; jj < Wr_diag_i[i+1]; jj++)
+      {
+         R_diag_j[r_offset] = F_map_data[Wr_diag_j[jj]];
+         R_diag_a[r_offset] = Wr_diag_a[jj];
+         r_offset++;
+      }
+   });
+#endif
+
+   /* 4. Free row_lengths */
+   hypre_TFree(row_lengths, HYPRE_MEMORY_DEVICE);
+
+   /* 5. Sync compute stream so that R_diag is ready for use */
+   hypre_SyncComputeStream();
+
+   return hypre_error_flag;
+}
+
 #endif
diff --git a/src/parcsr_ls/par_mgr_interp.c b/src/parcsr_ls/par_mgr_interp.c
index a1e2019a5..e2135b66e 100644
--- a/src/parcsr_ls/par_mgr_interp.c
+++ b/src/parcsr_ls/par_mgr_interp.c
@@ -786,10 +786,10 @@ hypre_MGRBuildPHost( hypre_ParCSRMatrix   *A,
          // L1-Jacobi-type interpolation
          diag_FF = hypre_CTAlloc(HYPRE_Complex, num_rows_AFF, memory_location_P);
          hypre_CSRMatrixExtractDiagonalHost(hypre_ParCSRMatrixDiag(A_FF), diag, 0);
-         hypre_CSRMatrixComputeRowSumHost(A_FF_diag, NULL, NULL, diag_FF, 1, 1.0, "set");
-         hypre_CSRMatrixComputeRowSumHost(A_FC_diag, NULL, NULL, diag_FF, 1, 1.0, "add");
-         hypre_CSRMatrixComputeRowSumHost(A_FF_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
-         hypre_CSRMatrixComputeRowSumHost(A_FC_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FF_diag, NULL, NULL, diag_FF, 1, 1.0, "set");
+         hypre_CSRMatrixComputeRowSum(A_FC_diag, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FF_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
+         hypre_CSRMatrixComputeRowSum(A_FC_offd, NULL, NULL, diag_FF, 1, 1.0, "add");
 
          for (i = 0; i < num_rows_AFF; i++)
          {
@@ -2405,14 +2405,7 @@ hypre_MGRBuildRFromWr(hypre_IntArray       *C_map,
 
    if (exec == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): Implement hypre_MGRBuildRFromWrDevice */
-      hypre_ParCSRMatrixMigrate(Wr, HYPRE_MEMORY_HOST);
-      hypre_ParCSRMatrixMigrate(R, HYPRE_MEMORY_HOST);
-      hypre_IntArrayMigrate(C_map, HYPRE_MEMORY_HOST);
-      hypre_IntArrayMigrate(F_map, HYPRE_MEMORY_HOST);
-      hypre_MGRBuildRFromWrHost(C_map, F_map, Wr, R);
-      hypre_ParCSRMatrixMigrate(Wr, HYPRE_MEMORY_DEVICE);
-      hypre_ParCSRMatrixMigrate(R, HYPRE_MEMORY_DEVICE);
+      hypre_MGRBuildRFromWrDevice(C_map, F_map, Wr, R);
    }
    else
 #endif
diff --git a/src/parcsr_ls/protos.h b/src/parcsr_ls/protos.h
index d9bfde521..b8621b197 100644
--- a/src/parcsr_ls/protos.h
+++ b/src/parcsr_ls/protos.h
@@ -2334,6 +2334,8 @@ HYPRE_Int hypre_ParCSRMatrixBlockDiagMatrixDevice( hypre_ParCSRMatrix *A, HYPRE_
                                                    HYPRE_Int point_type, HYPRE_Int *CF_marker,
                                                    HYPRE_Int diag_type,
                                                    hypre_ParCSRMatrix **B_ptr );
+HYPRE_Int hypre_MGRBuildRFromWrDevice(hypre_IntArray *C_map, hypre_IntArray *F_map,
+                                      hypre_ParCSRMatrix *Wr, hypre_ParCSRMatrix *R);
 
 /* par_mgr_stats.c */
 HYPRE_Int hypre_MGRSetupStats( void *mgr_vdata );
diff --git a/src/parcsr_mv/_hypre_parcsr_mv.h b/src/parcsr_mv/_hypre_parcsr_mv.h
index a83178afc..4896a6e1c 100644
--- a/src/parcsr_mv/_hypre_parcsr_mv.h
+++ b/src/parcsr_mv/_hypre_parcsr_mv.h
@@ -1037,6 +1037,7 @@ HYPRE_Int hypre_ParCSRDiagScaleVectorHost( hypre_ParCSRMatrix *par_A, hypre_ParV
                                            hypre_ParVector *par_x );
 HYPRE_Int hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A, hypre_ParVector *par_y,
                                              hypre_ParVector *par_x );
+HYPRE_Int hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A, hypre_ParVector *b );
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntries( hypre_ParCSRMatrix *A, HYPRE_Real tol,
                                               HYPRE_Int type);
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntriesHost( hypre_ParCSRMatrix *A, HYPRE_Real tol,
diff --git a/src/parcsr_mv/par_csr_matop.c b/src/parcsr_mv/par_csr_matop.c
index 8ce40413b..f03752330 100644
--- a/src/parcsr_mv/par_csr_matop.c
+++ b/src/parcsr_mv/par_csr_matop.c
@@ -7033,12 +7033,7 @@ hypre_ParCSRMatrixColSum( hypre_ParCSRMatrix   *A,
 
    if (exec == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): hypre_ParCSRMatrixColSumDevice */
-      hypre_ParCSRMatrixMigrate(A, HYPRE_MEMORY_HOST);
-      hypre_ParVectorMigrate(b, HYPRE_MEMORY_HOST);
-      hypre_ParCSRMatrixColSumHost(A, b);
-      hypre_ParCSRMatrixMigrate(A, HYPRE_MEMORY_DEVICE);
-      hypre_ParVectorMigrate(b, HYPRE_MEMORY_DEVICE);
+      hypre_ParCSRMatrixColSumDevice(A, b);
    }
    else
 #endif
@@ -7104,6 +7099,7 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
    HYPRE_Real              *tnorms          = NULL;
    HYPRE_Real              *weights         = NULL;
    HYPRE_Real              *g_weights       = NULL;
+   HYPRE_Real               tnorm;
    HYPRE_Int                i;
 
    /* Sanity check - Return an empty scaling if tags is a null pointer or type = 0 */
@@ -7138,7 +7134,8 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
       weights = hypre_TAlloc(HYPRE_Real, num_tags, HYPRE_MEMORY_HOST);
       for (i = 0; i < num_tags; i++)
       {
-         weights[i] = hypre_squared(tnorms[i * num_tags + i]);
+         tnorm = tnorms[i * num_tags + i];
+         weights[i] = (tnorm > 0.0) ? hypre_squared(tnorm) : 1.0;
       }
 
       /* Compute global scaling weights */
@@ -7149,6 +7146,17 @@ hypre_ParCSRMatrixCompScalingTagged(hypre_ParCSRMatrix  *A,
          g_weights[i] = pow(10.0, round(log10(hypre_sqrt(1.0 / g_weights[i]))));
       }
 
+#if 0
+      /* Debug weights */
+      hypre_ParPrintf(comm, "%s - Scaling weights: [ ", __func__);
+      for (i = 0; i < num_tags; i++)
+      {
+         hypre_ParPrintf(comm, "%.0e ", g_weights[i]);
+      }
+      hypre_ParPrintf(comm, "]\n");
+      hypre_MPI_Barrier(comm);
+#endif
+
       /* Setup scaling vector */
       for (i = 0; i < num_rows; i++)
       {
diff --git a/src/parcsr_mv/par_csr_matop_device.c b/src/parcsr_mv/par_csr_matop_device.c
index 77fdd6503..94ecdd16a 100644
--- a/src/parcsr_mv/par_csr_matop_device.c
+++ b/src/parcsr_mv/par_csr_matop_device.c
@@ -2025,4 +2025,88 @@ hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A,
+                                hypre_ParVector    *b )
+{
+   hypre_ParCSRCommPkg    *comm_pkg       = hypre_ParCSRMatrixCommPkg(A);
+   hypre_CSRMatrix        *A_diag         = hypre_ParCSRMatrixDiag(A);
+   hypre_CSRMatrix        *A_offd         = hypre_ParCSRMatrixOffd(A);
+   HYPRE_Int               num_cols_diag  = hypre_CSRMatrixNumCols(A_diag);
+   HYPRE_Int               num_cols_offd  = hypre_CSRMatrixNumCols(A_offd);
+   HYPRE_Complex          *b_data         = hypre_ParVectorLocalData(b);
+   HYPRE_Int               num_sends      = hypre_ParCSRCommPkgNumSends(comm_pkg);
+   HYPRE_Int               send_map_num_elmts = hypre_ParCSRCommPkgSendMapStart(comm_pkg, num_sends);
+
+   hypre_ParCSRCommHandle *comm_handle;
+   HYPRE_Complex          *d_send_buf;
+   HYPRE_Complex          *d_recv_buf;
+
+   /*---------------------------------------------------------------------
+    * Allocate/reuse data buffers
+    *--------------------------------------------------------------------*/
+
+   if (!hypre_ParCSRCommPkgTmpData(comm_pkg))
+   {
+      hypre_ParCSRCommPkgTmpData(comm_pkg) = hypre_TAlloc(HYPRE_Complex,
+                                                          num_cols_offd,
+                                                          HYPRE_MEMORY_DEVICE);
+   }
+   d_send_buf = hypre_ParCSRCommPkgTmpData(comm_pkg);
+   hypreDevice_ComplexFilln(d_send_buf, num_cols_offd, 0.0);
+
+   /* send_map_elmts on device */
+   hypre_ParCSRCommPkgCopySendMapElmtsToDevice(comm_pkg);
+
+   /* Allocate receive data buffer */
+   if (!hypre_ParCSRCommPkgBufData(comm_pkg))
+   {
+      hypre_ParCSRCommPkgBufData(comm_pkg) = hypre_TAlloc(HYPRE_Complex,
+                                                          send_map_num_elmts,
+                                                          HYPRE_MEMORY_DEVICE);
+   }
+   d_recv_buf = hypre_ParCSRCommPkgBufData(comm_pkg);
+
+   /*---------------------------------------------------------------------
+    * Overlap communication and computation
+    *--------------------------------------------------------------------*/
+
+   /* Compute off-diagonal contribution to be sent to neighboring ranks */
+   hypre_CSRMatrixComputeColSum(A_offd, d_send_buf, 0, 1.0);
+
+   /* Make sure d_send_buf is ready before communicating it */
+   if (hypre_GetGpuAwareMPI())
+   {
+      hypre_ForceSyncComputeStream();
+   }
+
+   /* Non-blocking communication starts */
+   comm_handle = hypre_ParCSRCommHandleCreate_v2(2, comm_pkg,
+                                                 HYPRE_MEMORY_DEVICE, d_send_buf,
+                                                 HYPRE_MEMORY_DEVICE, d_recv_buf );
+
+   /* Compute diagonal contribution */
+   hypre_CSRMatrixComputeColSum(A_diag, b_data, 0, 1.0);
+
+   /* Non-blocking communication ends */
+   hypre_ParCSRCommHandleDestroy(comm_handle);
+
+   /* Make sure b_data is ready before updating it below */
+   if (hypre_GetGpuAwareMPI())
+   {
+      hypre_ForceSyncComputeStream();
+   }
+
+   /* Compute off-diagonal contribution by unpacking data via SpMV */
+   hypre_ParCSRMatrixMatvecT_unpack(comm_pkg, num_cols_diag, d_recv_buf, b_data);
+
+   /* Final sync to ensure all updates are complete before returning */
+   hypre_SyncComputeStream();
+
+   return hypre_error_flag;
+}
+
 #endif // #if defined(HYPRE_USING_GPU) || defined(HYPRE_USING_DEVICE_OPENMP)
diff --git a/src/parcsr_mv/protos.h b/src/parcsr_mv/protos.h
index 02479f140..bf8bf95d9 100644
--- a/src/parcsr_mv/protos.h
+++ b/src/parcsr_mv/protos.h
@@ -373,6 +373,7 @@ HYPRE_Int hypre_ParCSRDiagScaleVectorHost( hypre_ParCSRMatrix *par_A, hypre_ParV
                                            hypre_ParVector *par_x );
 HYPRE_Int hypre_ParCSRDiagScaleVectorDevice( hypre_ParCSRMatrix *par_A, hypre_ParVector *par_y,
                                              hypre_ParVector *par_x );
+HYPRE_Int hypre_ParCSRMatrixColSumDevice( hypre_ParCSRMatrix *A, hypre_ParVector *b );
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntries( hypre_ParCSRMatrix *A, HYPRE_Real tol,
                                               HYPRE_Int type);
 HYPRE_Int hypre_ParCSRMatrixDropSmallEntriesHost( hypre_ParCSRMatrix *A, HYPRE_Real tol,
diff --git a/src/seq_mv/csr_matop.c b/src/seq_mv/csr_matop.c
index 5d614cdcb..ffc5e97a0 100644
--- a/src/seq_mv/csr_matop.c
+++ b/src/seq_mv/csr_matop.c
@@ -1832,7 +1832,7 @@ hypre_CSRMatrixFnorm( hypre_CSRMatrix *A )
  *         2, square sum
  *--------------------------------------------------------------------------*/
 
-void
+HYPRE_Int
 hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A,
                                   HYPRE_Int       *CF_i,
                                   HYPRE_Int       *CF_j,
@@ -1875,13 +1875,15 @@ hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A,
 
       row_sum[i] = row_sum_i;
    }
+
+   return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
  * hypre_CSRMatrixComputeRowSum
  *--------------------------------------------------------------------------*/
 
-void
+HYPRE_Int
 hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A,
                               HYPRE_Int       *CF_i,
                               HYPRE_Int       *CF_j,
@@ -1904,6 +1906,152 @@ hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A,
    {
       hypre_CSRMatrixComputeRowSumHost(A, CF_i, CF_j, row_sum, type, scal, set_or_add);
    }
+
+   return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ * Computes the column sums of a matrix.
+ * Assumes the input vector col_sum has size num_cols and equal to zeroes.
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSumHost( hypre_CSRMatrix *A,
+                                  HYPRE_Complex   *col_sum,
+                                  HYPRE_Int        type,
+                                  HYPRE_Complex    scal)
+{
+   HYPRE_Int      num_rows = hypre_CSRMatrixNumRows(A);
+   HYPRE_Int      num_cols = hypre_CSRMatrixNumCols(A);
+   HYPRE_Int     *rownnz   = hypre_CSRMatrixRownnz(A);
+   HYPRE_Complex *A_data   = hypre_CSRMatrixData(A);
+   HYPRE_Int     *A_i      = hypre_CSRMatrixI(A);
+   HYPRE_Int     *A_j      = hypre_CSRMatrixJ(A);
+
+#ifdef HYPRE_USING_OPENMP
+   #pragma omp parallel
+#endif
+   {
+      HYPRE_Int      tid = hypre_GetThreadNum();
+      HYPRE_Int      num_threads = hypre_NumActiveThreads();
+      HYPRE_Int      i, ii, j, col, ns, ne;
+      HYPRE_Complex *work;
+
+      /* Compute rows partitioning */
+      hypre_partition1D(num_rows, num_threads, tid, &ns, &ne);
+
+      /* Allocate work data */
+      work = (num_threads == 1) ?
+             col_sum : hypre_CTAlloc(HYPRE_Complex, num_cols, HYPRE_MEMORY_HOST);
+
+      switch (type)
+      {
+         case 0:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * A_data[j];
+               }
+            }
+            break;
+         }
+
+         case 1:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * hypre_cabs(A_data[j]);
+               }
+            }
+            break;
+         }
+
+         case 2:
+         {
+            for (i = ns; i < ne; i++)
+            {
+               ii = rownnz ? rownnz[i] : i;
+
+               for (j = A_i[ii]; j < A_i[ii + 1]; j++)
+               {
+                  hypre_assert(A_j[j] < num_cols);
+                  col = A_j[j];
+
+                  work[col] += scal * A_data[j] * A_data[j];
+               }
+            }
+            break;
+         }
+      }
+
+      /* Reduce results */
+      if (num_threads > 1)
+      {
+         for (i = 0; i < num_threads; i++)
+         {
+            if (i == tid)
+            {
+               for (j = 0; j < num_cols; j++)
+               {
+                  col_sum[j] = work[j];
+               }
+            }
+#ifdef HYPRE_USING_OPENMP
+            #pragma omp barrier
+#endif
+         }
+
+         hypre_TFree(work, HYPRE_MEMORY_HOST);
+      }
+   }
+
+   return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A,
+                              HYPRE_Complex   *col_sum,
+                              HYPRE_Int        type,
+                              HYPRE_Complex    scal)
+
+{
+   /* Trivial case */
+   if (!hypre_CSRMatrixNumCols(A))
+   {
+      return hypre_error_flag;
+   }
+
+#if defined(HYPRE_USING_GPU)
+   HYPRE_ExecutionPolicy exec = hypre_GetExecPolicy1( hypre_CSRMatrixMemoryLocation(A) );
+
+   if (exec == HYPRE_EXEC_DEVICE)
+   {
+      hypre_CSRMatrixComputeColSumDevice(A, col_sum, type, scal);
+   }
+   else
+#endif
+   {
+      hypre_CSRMatrixComputeColSumHost(A, col_sum, type, scal);
+   }
+
+   return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
@@ -2214,6 +2362,7 @@ hypre_CSRMatrixSetConstantValues( hypre_CSRMatrix *A,
 
 /*--------------------------------------------------------------------------
  * Computes the Frobenius norm for each tag in a CSR matrix.
+ *
  * Each row is assigned a tag (block identifier) via the tags array (local rows only).
  * The result is stored in the output pointer tnorms_ptr (length num_tags * num_tags).
  *--------------------------------------------------------------------------*/
@@ -2222,7 +2371,7 @@ HYPRE_Int
 hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
                                HYPRE_Int         num_tags,
                                HYPRE_Int        *tags,
-                               HYPRE_Real      **tnorms_ptr)
+                               HYPRE_Real       *tnorms)
 {
    HYPRE_Int       *A_i         = hypre_CSRMatrixI(A);
    HYPRE_Int       *A_j         = hypre_CSRMatrixJ(A);
@@ -2232,27 +2381,6 @@ hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
    HYPRE_Int        tnorms_size = num_tags * num_tags;
    HYPRE_Int        i, j, itag, jtag;
 
-   /* Create tnorms array */
-   if (!*tnorms_ptr)
-   {
-      *tnorms_ptr = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_HOST);
-   }
-   else
-   {
-      /* Initialize tnorms array */
-      for (i = 0; i < tnorms_size; i++)
-      {
-         (*tnorms_ptr)[i] = 0.0;
-      }
-   }
-
-   /* Call regular Frobenius norm if no tags or only one tag */
-   if (num_tags <= 1 || !tags)
-   {
-      (*tnorms_ptr)[0] = hypre_CSRMatrixFnorm(A);
-      return hypre_error_flag;
-   }
-
    /* Accumulate sums */
    for (i = 0; i < num_rows; i++)
    {
@@ -2263,43 +2391,64 @@ hypre_CSRMatrixTaggedFnormHost(hypre_CSRMatrix  *A,
       {
          jtag = tags[A_j[j]];
          hypre_assert(jtag >= 0 && jtag < num_tags);
-         (*tnorms_ptr)[itag * num_tags + jtag] += hypre_squared(A_a[j]);
+         tnorms[itag * num_tags + jtag] += hypre_squared(A_a[j]);
       }
    }
 
    /* Take square root for each block */
    for (i = 0; i < tnorms_size; i++)
    {
-      (*tnorms_ptr)[i] = hypre_sqrt((*tnorms_ptr)[i]);
+      tnorms[i] = hypre_sqrt(tnorms[i]);
    }
 
    return hypre_error_flag;
 }
 
 /*--------------------------------------------------------------------------
- * hypre_CSRMatrixTaggedFnorm
+ * Compute tagged Frobenius norms of an input matrix
  *--------------------------------------------------------------------------*/
 
 HYPRE_Int
-hypre_CSRMatrixTaggedFnorm(hypre_CSRMatrix *A,
-                           HYPRE_Int        num_tags,
-                           HYPRE_Int       *tags,
+hypre_CSRMatrixTaggedFnorm(hypre_CSRMatrix  *A,
+                           HYPRE_Int         num_tags,
+                           HYPRE_Int        *tags,
                            HYPRE_Real      **tnorms_ptr)
 {
+   HYPRE_Int     tnorms_size = num_tags * num_tags;
+   HYPRE_Int     i;
+
+   /* Create tnorms array */
+   if (!*tnorms_ptr)
+   {
+      *tnorms_ptr = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_HOST);
+   }
+   else
+   {
+      /* Initialize tnorms array */
+      for (i = 0; i < tnorms_size; i++)
+      {
+         (*tnorms_ptr)[i] = 0.0;
+      }
+   }
+
+   /* Call regular Frobenius norm if no tags or only one tag */
+   if (num_tags <= 1 || !tags)
+   {
+      (*tnorms_ptr)[0] = hypre_CSRMatrixFnorm(A);
+      return hypre_error_flag;
+   }
+
 #if defined(HYPRE_USING_GPU)
    HYPRE_MemoryLocation memory_location = hypre_CSRMatrixMemoryLocation(A);
 
    if (hypre_GetExecPolicy1(memory_location) == HYPRE_EXEC_DEVICE)
    {
-      /* TODO (VPM): hypre_ParCSRMatrixTaggedFnormDevice */
-      hypre_CSRMatrixMigrate(A, HYPRE_MEMORY_HOST);
-      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, tnorms_ptr);
-      hypre_CSRMatrixMigrate(A, HYPRE_MEMORY_DEVICE);
+      hypre_CSRMatrixTaggedFnormDevice(A, num_tags, tags, *tnorms_ptr);
    }
    else
 #endif
    {
-      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, tnorms_ptr);
+      hypre_CSRMatrixTaggedFnormHost(A, num_tags, tags, *tnorms_ptr);
    }
 
    return hypre_error_flag;
diff --git a/src/seq_mv/csr_matop_device.c b/src/seq_mv/csr_matop_device.c
index c5ad8ece1..890338719 100644
--- a/src/seq_mv/csr_matop_device.c
+++ b/src/seq_mv/csr_matop_device.c
@@ -1327,6 +1327,220 @@ hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A,
    return hypre_error_flag;
 }
 
+/*--------------------------------------------------------------------------
+ * GPU kernel for computing the column sums of a CSR matrix.
+ *
+ * Each warp processes one row and accumulates into shared memory.
+ *--------------------------------------------------------------------------*/
+
+template <HYPRE_Int type>
+__global__ void
+hypreGPUKernel_CSRMatrixComputeColSum(hypre_DeviceItem    &item,
+                                      HYPRE_Int            nrows,
+                                      HYPRE_Int            ncols,
+                                      const HYPRE_Int     *ia,
+                                      const HYPRE_Int     *ja,
+                                      const HYPRE_Complex *aa,
+                                      const HYPRE_Complex  scal,
+                                      HYPRE_Complex       *col_sum)
+{
+   /* Get warp and lane IDs */
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int num_warps = item.get_group(2) / HYPRE_WARP_SIZE;
+#else
+   const HYPRE_Int num_warps = blockDim.x / HYPRE_WARP_SIZE;
+#endif
+   const HYPRE_Int warp_id = hypre_gpu_get_warp_id<1>(item);
+   const HYPRE_Int lane_id = hypre_gpu_get_lane_id<1>(item);
+   const HYPRE_Int warp_in_block = warp_id % num_warps;
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int row = item.get_group(2) * num_warps + warp_in_block;
+#else
+   const HYPRE_Int row = blockIdx.x * num_warps + warp_in_block;
+#endif
+
+   if (row < nrows)
+   {
+      /* Load row bounds using warp shuffle */
+      HYPRE_Int p = 0, q = 0;
+      if (lane_id < 2)
+      {
+         p = read_only_load(ia + row + lane_id);
+      }
+      q = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 1);
+      p = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 0);
+
+      /* Process row elements using warp-level parallelism */
+      for (HYPRE_Int j = p + lane_id; j < q; j += HYPRE_WARP_SIZE)
+      {
+         HYPRE_Int     col = read_only_load(ja + j);
+         HYPRE_Complex val = read_only_load(aa + j);
+         HYPRE_Complex colsum = 0.0;
+
+         if (type == 0)
+         {
+            colsum = scal * val;
+         }
+         else if (type == 1)
+         {
+            colsum = scal * hypre_abs(val);
+         }
+         else if (type == 2)
+         {
+            colsum = scal * val * val;
+         }
+
+         /* Atomic add is required to prevent race conditions, as multiple warps
+           (processing different rows) may update the same column sum simultaneously. */
+         hypre_gpu_atomicAdd(col, col_sum, colsum);
+      }
+   }
+}
+
+/*--------------------------------------------------------------------------
+ * Computes column-wise sum of a CSR matrix on the device.
+ *
+ * type == 0, sum
+ *         1, abs sum (L1-norm)
+ *         2, square sum (L2-norm squared)
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixComputeColSumDevice(hypre_CSRMatrix  *A,
+                                   HYPRE_Complex    *col_sum,
+                                   HYPRE_Int         type,
+                                   HYPRE_Complex     scal)
+{
+    HYPRE_Int       nrows = hypre_CSRMatrixNumRows(A);
+    HYPRE_Int       ncols = hypre_CSRMatrixNumCols(A);
+    HYPRE_Int      *A_i   = hypre_CSRMatrixI(A);
+    HYPRE_Int      *A_j   = hypre_CSRMatrixJ(A);
+    HYPRE_Complex  *A_a   = hypre_CSRMatrixData(A);
+
+    /* Use standard block dimensions */
+    dim3 bDim = hypre_GetDefaultDeviceBlockDimension();
+    dim3 gDim = hypre_GetDefaultDeviceGridDimension(nrows, "warp", bDim);
+
+    /* Launch kernel based on type */
+    if (type == 0)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<0>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+    else if (type == 1)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<1>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+    else if (type == 2)
+    {
+        HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixComputeColSum<2>, gDim, bDim,
+                         nrows, ncols, A_i, A_j, A_a, scal, col_sum);
+    }
+
+    hypre_SyncComputeStream();
+
+    return hypre_error_flag;
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+__global__ void
+hypreGPUKernel_CSRMatrixTaggedFnormAccum(hypre_DeviceItem    &item,
+                                         const HYPRE_Int      nrows,
+                                         const HYPRE_Int      num_tags,
+                                         const HYPRE_Int     *tags,
+                                         const HYPRE_Int     *ia,
+                                         const HYPRE_Int     *ja,
+                                         const HYPRE_Complex *aa,
+                                         HYPRE_Real          *tnorms)
+{
+   /* Get warp and lane IDs */
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int num_warps     = item.get_group(2) / HYPRE_WARP_SIZE;
+#else
+   const HYPRE_Int num_warps     = blockDim.x / HYPRE_WARP_SIZE;
+#endif
+   const HYPRE_Int warp_id       = hypre_gpu_get_warp_id<1>(item);
+   const HYPRE_Int lane_id       = hypre_gpu_get_lane_id<1>(item);
+   const HYPRE_Int warp_in_block = warp_id % num_warps;
+#if defined (HYPRE_USING_SYCL)
+   const HYPRE_Int row  = item.get_group(2) * num_warps + warp_in_block;
+#else
+   const HYPRE_Int row  = blockIdx.x * num_warps + warp_in_block;
+#endif
+   const HYPRE_Int itag = tags[row];
+
+   if (row < nrows)
+   {
+      /* Load row bounds using warp shuffle */
+      HYPRE_Int p = 0, q = 0;
+      if (lane_id < 2)
+      {
+         p = read_only_load(ia + row + lane_id);
+      }
+      q = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 1);
+      p = warp_shuffle_sync(item, HYPRE_WARP_FULL_MASK, p, 0);
+
+      /* Process row elements using warp-level parallelism */
+      for (HYPRE_Int j = p + lane_id; j < q; j += HYPRE_WARP_SIZE)
+      {
+         HYPRE_Int     col  = read_only_load(ja + j);
+         HYPRE_Int     jtag = tags[col];
+         HYPRE_Complex val  = read_only_load(aa + j);
+
+         hypre_gpu_atomicAdd(itag * num_tags + jtag, tnorms, hypre_squared(val));
+      }
+   }
+}
+
+/*--------------------------------------------------------------------------
+ *--------------------------------------------------------------------------*/
+
+HYPRE_Int
+hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix  *A,
+                                 HYPRE_Int         num_tags,
+                                 HYPRE_Int        *tags,
+                                 HYPRE_Real       *tnorms)
+{
+   HYPRE_Int       num_rows    = hypre_CSRMatrixNumRows(A);
+   HYPRE_Int      *A_i         = hypre_CSRMatrixI(A);
+   HYPRE_Int      *A_j         = hypre_CSRMatrixJ(A);
+   HYPRE_Complex  *A_a         = hypre_CSRMatrixData(A);
+
+   HYPRE_Int       tnorms_size = num_tags * num_tags;
+   HYPRE_Int       i;
+   HYPRE_Int      *d_tags;
+   HYPRE_Real     *d_tnorms;
+
+   /* Allocate device buffers */
+   d_tnorms = hypre_CTAlloc(HYPRE_Real, tnorms_size, HYPRE_MEMORY_DEVICE);
+   d_tags   = hypre_CTAlloc(HYPRE_Int, num_rows, HYPRE_MEMORY_DEVICE);
+   hypre_TMemcpy(d_tags, tags, HYPRE_Int, num_rows,
+                 HYPRE_MEMORY_DEVICE, HYPRE_MEMORY_HOST);
+
+   /* Launch accumulation kernel */
+   dim3 bDim = hypre_GetDefaultDeviceBlockDimension();
+   dim3 gDim = hypre_GetDefaultDeviceGridDimension(num_rows, "wap", bDim);
+   HYPRE_GPU_LAUNCH(hypreGPUKernel_CSRMatrixTaggedFnormAccum, gDim, bDim,
+                    num_rows, num_tags, d_tags, A_i, A_j, A_a, d_tnorms);
+
+   /* Copy back to host and free device buffer */
+   hypre_TMemcpy(tnorms, d_tnorms, HYPRE_Real, tnorms_size,
+                 HYPRE_MEMORY_HOST, HYPRE_MEMORY_DEVICE);
+   hypre_TFree(d_tnorms, HYPRE_MEMORY_DEVICE);
+   hypre_TFree(d_tags, HYPRE_MEMORY_DEVICE);
+
+   /* Take square root for each block */
+   for (i = 0; i < tnorms_size; i++)
+   {
+      tnorms[i] = hypre_sqrt(tnorms[i]);
+   }
+
+   return hypre_error_flag;
+}
+
 /*--------------------------------------------------------------------------
  * hypreGPUKernel_CSRMatrixIntersectPattern
  *
diff --git a/src/seq_mv/protos.h b/src/seq_mv/protos.h
index 42ec225a3..016677820 100644
--- a/src/seq_mv/protos.h
+++ b/src/seq_mv/protos.h
@@ -40,10 +40,11 @@ HYPRE_Int hypre_CSRMatrixSplit(hypre_CSRMatrix *Bs_ext, HYPRE_BigInt first_col_d
                                hypre_CSRMatrix **Bext_offd_ptr);
 hypre_CSRMatrix * hypre_CSRMatrixAddPartial( hypre_CSRMatrix *A, hypre_CSRMatrix *B,
                                              HYPRE_Int *row_nums);
-void hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                       HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
-void hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                   HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
+HYPRE_Int hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
+                                        HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal,
+                                        const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A, HYPRE_Complex *col_sum,
+                                        HYPRE_Int type, HYPRE_Complex scal );
 HYPRE_Int hypre_CSRMatrixExtractDiagonal( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalHost( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixScale(hypre_CSRMatrix *A, HYPRE_Complex scalar);
@@ -86,6 +87,10 @@ HYPRE_Int hypre_CSRMatrixReplaceDiagDevice( hypre_CSRMatrix *A, HYPRE_Complex *n
 HYPRE_Int hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
                                               HYPRE_Complex *row_sum, HYPRE_Int type,
                                               HYPRE_Complex scal, const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSumDevice( hypre_CSRMatrix *A,  HYPRE_Complex *col_sum,
+                                              HYPRE_Int type, HYPRE_Complex scal );
+HYPRE_Int hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix *A, HYPRE_Int num_tags,
+                                           HYPRE_Int *tags, HYPRE_Real *tnorms);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalDevice( hypre_CSRMatrix *A, HYPRE_Complex *d,
                                                 HYPRE_Int type );
 hypre_CSRMatrix* hypre_CSRMatrixStack2Device(hypre_CSRMatrix *A, hypre_CSRMatrix *B);
diff --git a/src/seq_mv/seq_mv.h b/src/seq_mv/seq_mv.h
index c262e0ab0..362e39c64 100644
--- a/src/seq_mv/seq_mv.h
+++ b/src/seq_mv/seq_mv.h
@@ -324,10 +324,11 @@ HYPRE_Int hypre_CSRMatrixSplit(hypre_CSRMatrix *Bs_ext, HYPRE_BigInt first_col_d
                                hypre_CSRMatrix **Bext_offd_ptr);
 hypre_CSRMatrix * hypre_CSRMatrixAddPartial( hypre_CSRMatrix *A, hypre_CSRMatrix *B,
                                              HYPRE_Int *row_nums);
-void hypre_CSRMatrixComputeRowSumHost( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                       HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
-void hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
-                                   HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal, const char *set_or_add);
+HYPRE_Int hypre_CSRMatrixComputeRowSum( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
+                                        HYPRE_Complex *row_sum, HYPRE_Int type, HYPRE_Complex scal,
+                                        const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSum( hypre_CSRMatrix *A, HYPRE_Complex *col_sum,
+                                        HYPRE_Int type, HYPRE_Complex scal );
 HYPRE_Int hypre_CSRMatrixExtractDiagonal( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalHost( hypre_CSRMatrix *A, HYPRE_Complex *d, HYPRE_Int type);
 HYPRE_Int hypre_CSRMatrixScale(hypre_CSRMatrix *A, HYPRE_Complex scalar);
@@ -370,6 +371,10 @@ HYPRE_Int hypre_CSRMatrixReplaceDiagDevice( hypre_CSRMatrix *A, HYPRE_Complex *n
 HYPRE_Int hypre_CSRMatrixComputeRowSumDevice( hypre_CSRMatrix *A, HYPRE_Int *CF_i, HYPRE_Int *CF_j,
                                               HYPRE_Complex *row_sum, HYPRE_Int type,
                                               HYPRE_Complex scal, const char *set_or_add );
+HYPRE_Int hypre_CSRMatrixComputeColSumDevice( hypre_CSRMatrix *A,  HYPRE_Complex *col_sum,
+                                              HYPRE_Int type, HYPRE_Complex scal );
+HYPRE_Int hypre_CSRMatrixTaggedFnormDevice(hypre_CSRMatrix *A, HYPRE_Int num_tags,
+                                           HYPRE_Int *tags, HYPRE_Real *tnorms);
 HYPRE_Int hypre_CSRMatrixExtractDiagonalDevice( hypre_CSRMatrix *A, HYPRE_Complex *d,
                                                 HYPRE_Int type );
 hypre_CSRMatrix* hypre_CSRMatrixStack2Device(hypre_CSRMatrix *A, hypre_CSRMatrix *B);
diff --git a/src/utilities/_hypre_utilities.hpp b/src/utilities/_hypre_utilities.hpp
index 9fc8d5acf..f71c99918 100644
--- a/src/utilities/_hypre_utilities.hpp
+++ b/src/utilities/_hypre_utilities.hpp
@@ -1305,6 +1305,14 @@ hypre_double atomicAdd(hypre_double* address, hypre_double val)
 }
 #endif
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   atomicAdd((T*)(address + pos), val);
+}
+
 // There are no *_sync functions in HIP
 #if defined(HYPRE_USING_HIP) || (CUDA_VERSION < 9000)
 
@@ -1845,6 +1853,19 @@ hypre_int hypre_gpu_get_grid_warp_id(hypre_DeviceItem &item)
           hypre_gpu_get_warp_id<bdim>(item);
 }
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   auto atomic_val = sycl::atomic_ref<T,
+                                      sycl::memory_order::relaxed,
+                                      sycl::memory_scope::device,
+                                      sycl::access::address_space::local_space > (address[pos]);
+   auto curr = atomic_val.load(sycl::memory_order::relaxed);
+   while (!atomic_val.compare_exchange_strong(curr, curr + val, sycl::memory_order::relaxed)) {}
+}
+
 /* sync the thread block */
 static __device__ __forceinline__
 void block_sync(hypre_DeviceItem &item)
diff --git a/src/utilities/device_utils.h b/src/utilities/device_utils.h
index b4a494767..4886f7d0e 100644
--- a/src/utilities/device_utils.h
+++ b/src/utilities/device_utils.h
@@ -1109,6 +1109,14 @@ hypre_double atomicAdd(hypre_double* address, hypre_double val)
 }
 #endif
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   atomicAdd((T*)(address + pos), val);
+}
+
 // There are no *_sync functions in HIP
 #if defined(HYPRE_USING_HIP) || (CUDA_VERSION < 9000)
 
@@ -1649,6 +1657,19 @@ hypre_int hypre_gpu_get_grid_warp_id(hypre_DeviceItem &item)
           hypre_gpu_get_warp_id<bdim>(item);
 }
 
+/* Perform atomic add operation */
+template <typename T>
+static __device__ __forceinline__
+void hypre_gpu_atomicAdd(hypre_int pos, T* address, T val)
+{
+   auto atomic_val = sycl::atomic_ref<T,
+                                      sycl::memory_order::relaxed,
+                                      sycl::memory_scope::device,
+                                      sycl::access::address_space::local_space > (address[pos]);
+   auto curr = atomic_val.load(sycl::memory_order::relaxed);
+   while (!atomic_val.compare_exchange_strong(curr, curr + val, sycl::memory_order::relaxed)) {}
+}
+
 /* sync the thread block */
 static __device__ __forceinline__
 void block_sync(hypre_DeviceItem &item)
